{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Laboratory 4: Partially observable Markov decision problems\n",
    "\n",
    "In the end of the lab, you should submit all code/answers written in the tasks marked as \"Activity n. XXX\", together with the corresponding outputs and any replies to specific questions posed to the e-mail <adi.tecnico@gmail.com>. Make sure that the subject is of the form [&lt;group n.&gt;] LAB &lt;lab n.&gt;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### 1. Modeling\n",
    "\n",
    "Consider once again the guessing game domain described in the Homework and which you described as a POMDP.\n",
    "\n",
    "Recall that:\n",
    "\n",
    "* The opponent can hold one of two cards in hand: an Ace of Clubs (A&clubs;) and an Ace of Diamonds (A&diams;). The agent must guess which card the opponent is holding. \n",
    "\n",
    "* For every right answer, the agent wins 1EUR, and every wrong answer costs the agent 1EUR. \n",
    "\n",
    "* The agent can also try to _peek_. \n",
    "\n",
    "* When the agent peeks, it sees the right card with a probability of 0.9 and the wrong card with probability 0.1.\n",
    "\n",
    "* The game restarts whenever the agent makes a guess.\n",
    "\n",
    "Consider throughout that $\\gamma=0.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Implement your POMDP in Python. In particular,\n",
    "\n",
    "* Create a list with all the states;\n",
    "* Create a list with all the actions;\n",
    "* Create a list with all the observations\n",
    "* For each action, define a `numpy` array with the corresponding transition probabilities;\n",
    "* For each action, define a `numpy` array with the corresponding observation probabilities;\n",
    "* Define a `numpy`array with the cost that you defined in your homework.\n",
    "\n",
    "The order for the states and actions used in the transition probability and cost matrices should match that in the lists of states and actions. \n",
    "\n",
    "**Note**: Don't forget to import `numpy`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "import numpy as np\n",
    "\n",
    "states = [\"Clubs\" , \"Diamonds\"]\n",
    "\n",
    "actions = [\"SelectClubs\", \"SelectDiamonds\", \"Peek\"]\n",
    "\n",
    "observations = [\"Clubs\", \"Diamonds\"]\n",
    "\n",
    "P_Peek = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "P_Clubs = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "P_Diamonds = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "\n",
    "O_Peek = np.array([[0.9, 0.1], [0.1, 0.9]])\n",
    "\n",
    "O_Clubs = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "O_Diamonds = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "Cost = np.array([[0, 1, 0.1], [1, 0, 0.1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Sampling\n",
    "\n",
    "You are now going to sample random trajectories of your POMDP and observe the impact it has on the corresponding belief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "raw_mimetype": "text/latex"
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 2.\n",
    "\n",
    "Generate a random POMDP trajectory using a uniformly random policy. In particular, from a random initial state $x_0$ generate:\n",
    "\n",
    "1. A sequence of 10,000 states by selecting the actions uniformly at random;\n",
    "2. The corresponding sequence of 10,000 actions;\n",
    "3. The corresponding sequence of 10,000 observations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATES(carta que esta na mao do oponente)\n",
      "\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Diamonds']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Diamonds']\n",
      "['Clubs']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "\n",
      "ACTIONS(accao que o agente escolhe)\n",
      "\n",
      "['Peek']\n",
      "['Peek']\n",
      "['Peek']\n",
      "['SelectDiamonds']\n",
      "['SelectClubs']\n",
      "['SelectClubs']\n",
      "['SelectDiamonds']\n",
      "['SelectDiamonds']\n",
      "['SelectDiamonds']\n",
      "['Peek']\n",
      "['Peek']\n",
      "['SelectDiamonds']\n",
      "['SelectDiamonds']\n",
      "['SelectDiamonds']\n",
      "['SelectClubs']\n",
      "['Peek']\n",
      "['SelectClubs']\n",
      "['SelectClubs']\n",
      "['SelectDiamonds']\n",
      "['SelectClubs']\n",
      "\n",
      "OBSERVATIONS(observacao que o agente faz)\n",
      "\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Diamonds']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Clubs']\n",
      "['Diamonds']\n",
      "['Clubs']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "['Diamonds']\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "t = 0\n",
    "\n",
    "initial_policy = np.array([[1./3, 1./3, 1./3], [1./3, 1./3, 1./3]])\n",
    "\n",
    "sequence_states = []\n",
    "sequence_actions = []\n",
    "sequence_observations = []\n",
    "\n",
    "\n",
    "# DUVIDA: depois de fazermos peek e observarmos algo \n",
    "# temos de actualizar de novo a observacao quando o oponente mostra que carta tem ?\n",
    "\n",
    "while t<20:\n",
    "    \n",
    "    state = np.random.choice(states,1, replace=False)\n",
    "    action = np.random.choice(actions,1, replace=False)\n",
    "    \n",
    "    if state == \"Clubs\":\n",
    "        observation_probabilities = O_Peek[:,0] # [0.9]\n",
    "                                                # [0.1]\n",
    "    else:\n",
    "        observation_probabilities = O_Peek[:,1] # [0.1]\n",
    "                                                # [0.9]\n",
    "    if action == \"Peek\":\n",
    "        observation = np.random.choice(observations,1, replace=False, p=observation_probabilities)\n",
    "    else:\n",
    "        # V1\n",
    "        observation = state # se a accao for adivinhar uma carta a nossa observacao\n",
    "                            # vai ser igual ao estado (que e a carta que esta na mao do oponente)\n",
    "        # V2\n",
    "        #observation = np.random.choice(observations,1, replace=False, p=np.array([0.5, 0.5]))\n",
    "\n",
    "    sequence_states += [state]\n",
    "    sequence_actions += [action]\n",
    "    sequence_observations += [observation]\n",
    "    t+=1\n",
    "    \n",
    "    \n",
    "print \"STATES(carta que esta na mao do oponente)\\n\"\n",
    "for i in sequence_states:\n",
    "    print i\n",
    "print \"\\nACTIONS(accao que o agente escolhe)\\n\"    \n",
    "for i in sequence_actions:\n",
    "    print i\n",
    "print \"\\nOBSERVATIONS(observacao que o agente faz)\\n\"\n",
    "for i in sequence_observations:\n",
    "    print i\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 3.\n",
    "\n",
    "For the POMDP trajectory generated in Activity 2, compute the corresponding sequence of beliefs, assuming that the initial belief is $\\mathbf{b}_0=[0.5, 0.5]$. Report the resulting beliefs, ignoring duplicate beliefs or beliefs whose distance is smaller than $10^{-4}$.\n",
    "\n",
    "**Note 1:** You may want to define a function `belief_update` that receives a belief, an action and an observation and returns the updated belief.\n",
    "\n",
    "**Note 2:** To compute the distance between vectors, you may find useful `numpy`'s function `linalg.norm`.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5]]\n",
      "[[ 0.1  0.9]]\n",
      "[[ 0.012  0.988]]\n",
      "[[ 0.001  0.999]]\n",
      "[[ 0.012  0.988]]\n",
      "[[ 0.1  0.9]]\n",
      "[[ 0.5  0.5]]\n",
      "[[ 0.1  0.9]]\n",
      "[[ 0.5  0.5]]\n",
      "[[ 0.9  0.1]]\n",
      "[[ 0.988  0.012]]\n",
      "[[ 0.999  0.001]]\n",
      "[[  9.998e-01   1.524e-04]]\n",
      "[[ 0.999  0.001]]\n",
      "[[  9.998e-01   1.524e-04]]\n",
      "[[ 0.999  0.001]]\n",
      "[[ 0.988  0.012]]\n",
      "[[ 0.9  0.1]]\n",
      "[[ 0.5  0.5]]\n",
      "[[ 0.1  0.9]]\n",
      "\n",
      "belief list without repetitions:\n",
      "[[ 0.5  0.5]]\n",
      "[[ 0.1  0.9]]\n",
      "[[ 0.012  0.988]]\n",
      "[[ 0.001  0.999]]\n",
      "[[ 0.9  0.1]]\n",
      "[[ 0.988  0.012]]\n",
      "[[ 0.999  0.001]]\n",
      "[[  9.998e-01   1.524e-04]]\n",
      "[[ 0.999  0.001]]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "initial_belief = np.array([[0.5, 0.5]])\n",
    "belief_list = [initial_belief]\n",
    "\n",
    "\n",
    "def belief_update(belief, action, observation):\n",
    "        \n",
    "    if action == \"Peek\":\n",
    "        \n",
    "        Pa = P_Peek\n",
    "        \n",
    "        if observation == \"Clubs\":\n",
    "            Diag_O = np.diag(O_Peek[:,0])\n",
    "        else:\n",
    "            Diag_O = np.diag(O_Peek[:,1])\n",
    "            \n",
    "    elif action == \"SelectClubs\" or action ==\"SelectDiamonds\":\n",
    "        \n",
    "        Pa = P_Clubs # Clubs e Diamonds tem P iguais por isso nao faz diferenca\n",
    "        \n",
    "        if observation == \"Clubs\":\n",
    "            Diag_O = np.diag(O_Peek[:,0])\n",
    "        else:\n",
    "            Diag_O = np.diag(O_Peek[:,1])\n",
    "\n",
    "    \n",
    "    aux1 = np.dot(belief, Pa * Diag_O) # belief * Pa * Diag_O\n",
    "    aux2 = aux1[:,0] + aux1[:,1] # [a, b] --> a+b\n",
    "\n",
    "    \n",
    "    updated_belief = aux1/aux2\n",
    "    \n",
    "    return updated_belief\n",
    " \n",
    "#print belief_update(initial_belief,\"Peek\",\"Diamonds\")\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "unique_belief_list = [initial_belief]\n",
    "\n",
    "\n",
    "for action, observation in zip(sequence_actions, sequence_observations):\n",
    "    \n",
    "    print initial_belief #so para a primeira belief aparecer tambem  \n",
    "    \n",
    "    new_belief = belief_update(initial_belief,action,observation)\n",
    "    \n",
    "    initial_belief = new_belief\n",
    "  \n",
    "    # CONFIRMAR ESTA CONDICAO\n",
    "    \n",
    "    \n",
    "    #print unique_belief_list\n",
    "    #print new_belief\n",
    "    #print np.all(unique_belief_list != new_belief)\n",
    "    if np.all(unique_belief_list != new_belief) and np.linalg.norm(new_belief) >= 1e-4:\n",
    "        unique_belief_list += [new_belief]\n",
    "        \n",
    "\n",
    "\n",
    "print \"\\nbelief list without repetitions:\"\n",
    "\n",
    "for i in unique_belief_list:\n",
    "    print i\n",
    "    \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Solution methods\n",
    "\n",
    "In this section you are going to compare different non-exact solution methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 4\n",
    "\n",
    "Compute the solution for the underlying MDP and report the corresponding optimal policy and optimal cost-to-go. \n",
    "\n",
    "** Note:** You may reuse code from previous labs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost to Go:\n",
      "[[ 3.667]\n",
      " [ 3.667]]\n",
      "Optimal Policy:\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "\n",
    "ident = np.eye(2)\n",
    "\n",
    "gamma = 0.9\n",
    "\n",
    "def calc_cost_to_go():\n",
    "    \n",
    "    pi = initial_policy\n",
    "    \n",
    "    # ja estao la em cima é so para me organizar melhor \n",
    "    P_Peek = np.array([[1, 0], [0, 1]])\n",
    "    P_Clubs = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "    P_Diamonds = np.array([[0.5, 0.5], [0.5, 0.5]]) \n",
    "    \n",
    "    \n",
    "    C_Peek = Cost[:,0][np.newaxis, :].T\n",
    "    C_Clubs = Cost[:,1][np.newaxis, :].T\n",
    "    C_Diamonds = Cost[:,2][np.newaxis, :].T\n",
    "\n",
    "    \n",
    "    Ppi = np.diag(pi[:,0]).dot(P_Peek) + \\\n",
    "          np.diag(pi[:,1]).dot(P_Clubs) + \\\n",
    "          np.diag(pi[:,2]).dot(P_Diamonds)\n",
    "          \n",
    "    \n",
    "    Cpi = np.diag(pi[:,0]).dot(C_Peek) + \\\n",
    "          np.diag(pi[:,1]).dot(C_Clubs) + \\\n",
    "          np.diag(pi[:,2]).dot(C_Diamonds)\n",
    "          \n",
    "                \n",
    "    \n",
    "    J = np.linalg.inv(np.eye(2) - gamma * Ppi).dot(Cpi)\n",
    "    \n",
    "    return J\n",
    "\n",
    "##########################################################\n",
    "##########################################################\n",
    "Qpeek = []\n",
    "Qclubs = []\n",
    "Qdiamonds = []\n",
    "\n",
    "policy_J_optimal = np.zeros((2,2))\n",
    "\n",
    "def calc_pol_iter():\n",
    "    \n",
    "    pi = initial_policy\n",
    "    #pi = np.array([[0, 0, 0], [0, 0, 0]])\n",
    "    \n",
    "    # ja estao la em cima é so para me organizar melhor \n",
    "    P_Peek = np.array([[1, 0], [0, 1]])\n",
    "    P_Clubs = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "    P_Diamonds = np.array([[0.5, 0.5], [0.5, 0.5]]) \n",
    "    \n",
    "    C_Peek = Cost[:,0]\n",
    "    C_Clubs = Cost[:,1]\n",
    "    C_Diamonds = Cost[:,2]\n",
    "\n",
    "    \n",
    "    quit = False \n",
    "    \n",
    "    while not quit:\n",
    "        \n",
    "\n",
    "        Ppi = np.diag(pi[:,0]).dot(P_Peek) + \\\n",
    "              np.diag(pi[:,1]).dot(P_Clubs) + \\\n",
    "              np.diag(pi[:,2]).dot(P_Diamonds)\n",
    "\n",
    "\n",
    "        Cpi = np.diag(pi[:,0]).dot(C_Peek) + \\\n",
    "              np.diag(pi[:,1]).dot(C_Clubs) + \\\n",
    "              np.diag(pi[:,2]).dot(C_Diamonds)\n",
    "                \n",
    "        J = np.linalg.inv(np.eye(2) - gamma * Ppi).dot(Cpi)\n",
    "        \n",
    "        Qpeek = C_Peek+ gamma * P_Peek.dot(J)\n",
    "        Qclubs = C_Clubs + gamma * P_Clubs.dot(J)\n",
    "        Qdiamonds = C_Diamonds + gamma * P_Diamonds.dot(J)\n",
    "        \n",
    "        \n",
    "        pinew = np.zeros((2,3))\n",
    "        \n",
    "        \n",
    "        pinew[:,0] = np.isclose(Qpeek, np.min([Qpeek, Qclubs, Qdiamonds], axis=0), atol=1e-10, rtol=1e-10).astype(int)\n",
    "        pinew[:,1] = np.isclose(Qclubs, np.min([Qpeek, Qclubs, Qdiamonds], axis=0), atol=1e-10, rtol=1e-10).astype(int)\n",
    "        pinew[:,2] = np.isclose(Qdiamonds, np.min([Qpeek, Qclubs, Qdiamonds], axis=0), atol=1e-10, rtol=1e-10).astype(int)        \n",
    "    \n",
    "        pinew = pinew / np.sum(pinew, axis=1, keepdims = True)\n",
    "        \n",
    "        quit = (pi == pinew).all()\n",
    "        pi = pinew\n",
    "    \n",
    "    \n",
    "\n",
    "    return pi\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "#######################\n",
    "\n",
    "cost_to_go = calc_cost_to_go()\n",
    "optimal_policy = calc_pol_iter()\n",
    "\n",
    "print \"Cost to Go:\"\n",
    "print cost_to_go\n",
    "print \"Optimal Policy:\"\n",
    "print optimal_policy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 5\n",
    "\n",
    "For each of the beliefs computed in Activity 3, compute the action prescribed by:\n",
    "\n",
    "* The MLS heuristic;\n",
    "* The AV heuristic;\n",
    "* The Q-MDP heuristic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLS Heuristic\n",
      "\n",
      "no action\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "\n",
      "AV Heuristic\n",
      "\n",
      "no action\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n",
    "def MLS(belief):\n",
    "    \n",
    "    if belief[:,0]>  b[:,1]:\n",
    "        return actions[0]\n",
    "    elif belief[:,0] < b[:,1]:\n",
    "        return actions[1]\n",
    "    else:\n",
    "        return \"no action\"\n",
    "    \n",
    "def AV(belief):\n",
    "    \n",
    "    clubs_weight = belief[:,0]\n",
    "    diamonds_weight = belief[:,1]\n",
    "    \n",
    "    if clubs_weight > diamonds_weight:\n",
    "        return actions[0]\n",
    "    elif clubs_weight < diamonds_weight:\n",
    "        return actions[1]\n",
    "    else:\n",
    "        return \"no action\"\n",
    "\n",
    "\n",
    "    \n",
    "print \"\\nMLS Heuristic\\n\"\n",
    "for b in unique_belief_list:\n",
    "    print MLS(b)\n",
    "   \n",
    "print \"\\nAV Heuristic\\n\"\n",
    "for b in unique_belief_list:\n",
    "    print AV(b)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 6\n",
    "\n",
    "Suppose that the optimal cost-to-go function for the POMDP can be represented using the $\\alpha$-vectors\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{bmatrix}\n",
    "2.795\\\\\n",
    "3.795\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "3.795\\\\\n",
    "2.795\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "3.105\\\\\n",
    "3.105\n",
    "\\end{bmatrix}\\right\\}$$\n",
    "\n",
    "corresponding to the actions 'Guess clubs', 'Guess diamonds' and 'Peek', respectively. Represent the optimal cost-to-go function and compare the optimal policy with the MDP heuristics from Activity 5 in the beliefs computed in Activity 3.\n",
    "\n",
    "** Note: ** Don't forget to import `matplotlib`, and use the magic `%matplotlib notebook`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3Xl8XNV9///X0b6P9s2yJEu2bFkGgxQIOwHbEJKGhARI\nBLSEtmlYAqnzLUn7bfttm9+v4UfSNE2XJE3SbE3qbt9fv6VJy2LAEMAGItU42LIkW9Zq7ctoHy1z\nvn/M2MhCGmtGo9FIej8fj3lgHZ1775mLrHn7c8+9x1hrEREREVlMxGoPQERERMKbwoKIiIj4pLAg\nIiIiPiksiIiIiE8KCyIiIuKTwoKIiIj4pLAgIiIiPiksiIiIiE8KCyIiIuKTwoKIiIj4tKywYIz5\nXWOM2xjz5xfp9z5jTI0xZtIY02CMuX85xxUREZHQCTgsGGOuAH4LeOsi/YqBnwLPA7uBrwPfNcbs\nC/TYIiIiEjoBhQVjTBLwY+A3gaGLdH8IaLLWft5aW2+t/RvgX4H9gRxbREREQivQysLfAP9hrX1h\nCX2vAg7Oa3sGuDrAY4uIiEgIRfm7gTHmE8BlwHuWuEku0D2vrRtIMcbEWmtdCxwjA7gVaAYm/R2j\niIjIBhYHFAPPWGv7g7FDv8KCMaYA+Atgr7V2OhgDWMStwE9WcP8iIiLr3b3APwRjR/5WFqqALKDW\nGGO8bZHADcaYzwCx1lo7b5suIGdeWw4wvFBVwasZ4Mc//jHl5eV+DlECtX//fr72ta+t9jA2FJ3z\n0NM5Dz2d89Cqq6vjvvvuA+9naTD4GxYOApfMa/sBUAf8fwsEBYDDwG3z2m7xti9mEqC8vJzKyko/\nhyiBcjgcOt8hpnMeejrnoadzvmqCdhnfr7BgrR0DTsxtM8aMAf3W2jrv118CNllrzz1L4VvAI8aY\nJ4HvAXuAO4EPLHPsIiIiEgLBeILj/GpCHrD5/DetbQY+COwFjuK5ZfI3rLXz75AQERGRMOT33RDz\nWWtvnvf1Awv0eRnPfAcRERFZY7Q2hJxXXV292kPYcHTOQ0/nPPR0ztc+s/CcxNVljKkEampqajQp\nRkRExA+1tbVUVVUBVFlra4OxT1UWRERExCeFBREREfFJYUFERER8UlgQERERnxQWRERExCeFBRER\nEfFJYUFERER8WvYTHFfS0MTQag9BRERkTXC5oL4ennkm+PsO67Cw50d7yDmcQ0V2BTszd1KRXUFF\nVgU7s3aSkZCx2sMTEREJuXOh4MQJOH7c8zpxAk6dgtnZlTlmWD/B8Yl/eoLxrHFO9J7geO9xGvsb\nmbWeM5GTqBAhIiLr11JCQW4uVFR4Xjt3ev47PV3LzTcH9wmOYR0W5j/u2TXjonGgkeM9xznee1wh\nQkRE1rxAQ8HOnZCe/u79rcTjnsP6MsR8sVGx7Mrexa7sXRe0LxQiDp45yDd/8U2FCBERCQv+hIJb\nb4X9+32HglBaU2FhMQoRIiISLtZyKFjMuggLi1GIEBGRlbIeQ8Fi1nVYWIxChIiILNVGCgWL2ZBh\nYTEKESIiG5dCweIUFpZAIUJEZP1QKPBfWIeFurExGBlZ7WH4Fl/EtqIithV9gI94m6Zmp2h1ttE0\neJrTg6dpGjzDTzvr+cbJ53BbNwDp8emUppWyJbWE0vQSStJKKUkrITXOsXrvRURkHZmagpYWaGqC\n003QdNrz57Y2cHt+FZORASWlcPnd8LESz59LtoBjgV/FzUBzmH8kgfezM8jC+jkL/O3fQlnZag9H\nRERk7WhogE9/GjbKcxZ+XF5O+WWXrfYwVtxClYimwdO0OltViRAR8fKnUlBaAiUXqRSsV3WRkdwX\n5H2GdVgoT0ykMjl5tYcRElelZkDRhcFooTkRx5r+lf/9pp5YKSLrlz9zCj5cATvv1JyCCyQmBn2X\nYR0WNjpNrBSR9UwTDdcOhYU1SCFCRNYShYK1T2FhHVGIEJHVpFCwfiksbAAKESISTAoFG4/Cwgam\nECEivigUyDl+hQVjzIPAQ0Cxt+k48EVr7dOL9L8ReHFeswXyrLU9/g1VQkUhQmRjUSiQi/G3stAG\nfAFoBAzwSeDfjTGXWWvrFtnGAmXA+edeKSisTQoRImubQoEEyq+wYK392bymPzDGPARcBSwWFgB6\nrbXD/g5O1gaFCJHwolAgwRbwnAVjTARwN5AAHPbVFThqjIkD3gb+2Fr7WqDHlbVDIUJkZSkUSKj4\nHRaMMbvwhIM4PJcW7rDWnlykeyfwaeAXQCzwKeCQMeZKa+3RwIYsa51ChIh/FApktfm9kJQxJgoo\nBBzAnXgCwA0+AsP87Q8BLdba+330qQRqbrjhBhzzHuhdXV1NdXW1X2OWtW2hEHG89ziN/Xrstawv\n/oSCc2FAoWBjO3DgAAcOHLigzel08vLLL0MQF5Ja9qqTxpjngFPW2oeW2P/LwLXW2mt99KkEampq\naqisrFzW+GT9UoiQtUqhQFZSbW0tVVVVEGarTkbgucSwVJfhuTwhsiy6nCHhTpcPZL3w9zkLXwL+\nC2gFkoF7gRuBW7zffwLIP3eJwRjzWeAMnucxxOG5ZHETsC9I4xd5F4UICTWFAlnv/K0sZAM/BPIA\nJ3AMuMVa+4L3+7nA5jn9Y4CvAvnAuLf/Hmvty8sZtEggFCJkuRQKZKNa9pyFlaA5CxIONCdi49Kc\nAlnLwnXOgsi6pErE+qdKgcjSKCyI+EkhYu1RKBBZHoUFkSBRiFh9CgUiK0NhQWSFKUQEn0KBSGgp\nLIisEoWIi1MoEAkPCgsiYWYjhgiFApHwprAgskashxChUCCyNiksiKxx4RgiFApE1heFBZF1KhQh\nQqFAZGNQWBDZYJYTIhyROaRNVxAxsJOxMxX0Hq/A3b0TJjIUCkTWMYUFEQE8IWKbYxfurl3YbrDH\nwX0cZk+6OD3YiDvjOM7s40wWnCAy7yAT7/km9gpPiMhOyGFnTgXlmTspz65gZ1YF5Vk7SQ/ziZUi\nsjQKCyIbkD+XD27bF8vOnbuoqNh1QaVgLU2sFJHlUVgQWcdWck5BOE6sFJGVobAgsg6E00RDhQiR\n9UdhQWQNCadQ4C+FCJG1S2FBJAyt5VDgL4UIkfCnsCCyijZSKPCXQoRI+FBYEAkBhYLgUYgQCT2F\nBZEgUihYPQoRIitHYUEkAAoFa4dChMjyKSyI+KBQsH4pRIgsncKCCAoF8g6FCJF3U1iQDUWhQAKl\nECEbmcKCrEsKBRIqChGyEYR3WKirW+0RSJibmoKWFmhqgtOnPf9taoK2Nph1e/pkZkBJCVx9OZR8\nzPPnkhJwOBbYYbP3JbJMscAuYBfbwLENHB+BrTA1M0XrcCtNA02cHjxN09kmmk78lCND32DWen5o\nM+LTKU0vZUvqFkrTSylJK6EktYTU+NRVfU+yRqzAZ6ex1gZ9p8tljKkEamqAytUejIiIyBpSC1R5\n/lhlra0Nxj7Du7Lw4x9Deflqj0JCyJ9KQWnpO1WCRSsFImvcuyoRg000DTXROtSqSoQsrK4O7rsv\nqLsM77BQXg6Vqi2sR/7MKaj4MNy6U3MKZGOKAbZyFVvntS80J+Kl3mM0Nv1vzYmQoPMrLBhjHgQe\nAoq9TceBL1prn/axzfuArwIVQCvwp9baHwYyWFl7NNFQZGVoYqWEkr+VhTbgC0AjYIBPAv9ujLnM\nWvuuGRXGmGLgp8A3gHuAvcB3jTFnrbXPBT5sCTcKBSLhQSFCVsKyJzgaY/qB37HWfn+B7z0J3Gat\nvXRO2wHAYa39gI99eiY41tRQqcsQYcWvywfeMKBQIBK+FgoRx3uP09jfqBCxRtXW1lJVVQXhMMHR\nGBMB3A0kAIcX6XYVcHBe2zPA1wI9roSGKgUiG4MqEbIUfocFY8wuPOEgDhgB7rDWnlykey7QPa+t\nG0gxxsRaa13+Hl+CS6FARBaiECFz+X0ZwhgTBRQCDuBO4FPADQsFBmNMPfA9a+2Tc9puwzOPIWGx\nsHDuMsQNN9yAY979cNXV1VRXV/s1ZtHlAxFZWbqcsToOHDjAgQMHLmhzOp28/PLLEMTLEMGYs/Ac\ncMpa+9AC33sJqLHWfm5O2yeBr1lr03zsU3MWAqRQICLhRCEi9MJqzsIcEXiebLqQw8Bt89puYfE5\nDrJEunwgImuBLmesD/4+Z+FLwH/heV5CMnAvcCOeAIAx5gkg31p7v3eTbwGPeO+K+B6wB8+li0Xv\nhJALKRSIyHqkELG2+FtZyAZ+COQBTuAYcIu19gXv93OBzec6W2ubjTEfxHP3w2NAO/Ab1tr5d0hs\neAoFIiIKEeEqvBeSWodzFjSnQEQkeDQn4t3Cdc6CLECVAhGRladKRGgoLCyTQoGISPhRiAguhYUl\nUigQEVn7FCICo7Awj0KBiMjGoxDh24YNCwoFIiJyMQoRHus+LCgUiIhIsG20ELFuwoJCgYiIrLb1\nGiLWXFhQKBARkbVmrYeIsH4o0z/+Yw3WVurhRSIisqEs52FTLSdbgv5QprAOC1ADVCoUiIiIsLQQ\nkT6YzsDXB2CjPMHxu9+FO+5QKBAREYGlXc44+OpBvst3g3rcsA4Ll1+uoCAiInIxc0PEtqltQQ8L\nEUHdm4iIiKw7CgsiIiLik8KCiIiI+KSwICIiIj4pLIiIiIhPCgsiIiLik8KCiIiI+KSwICIiIj4p\nLIiIiIhPCgsiIiLik8KCiIiI+KSwICIiIj4pLIiIiIhPCgsiIiLik8KCiIiI+ORXWDDG/J4x5g1j\nzLAxptsY82/GmLKLbHOjMcY97zVrjMle3tBFREQkFPytLFwP/BXwXmAvEA08a4yJv8h2FtgG5Hpf\nedbaHj+PLSIiIqsgyp/O1toPzP3aGPNJoAeoAl65yOa91tphv0YnIiIiq265cxZS8VQNBi7SzwBH\njTFnjTHPGmOuWeZxRUREJEQCDgvGGAP8BfCKtfaEj66dwKeBjwEfBdqAQ8aYywI9toiIiISOX5ch\n5vkGsBO41lcna20D0DCn6YgxphTYD9y/jOOLiIhICAQUFowxfw18ALjeWtsZwC7e4CIhA2D//v04\nHI4L2qqrq6murg7gkCIiIuvLgQMHOHDgwAVtTqcz6Mcx1lr/NvAEhQ8DN1prmwI6qDHPAsPW2jsX\n+X4lUFNTU0NlZWUghxAREdmQamtrqaqqAqiy1tYGY59+VRaMMd8AqoHbgTFjTI73W05r7aS3z5eA\nTdba+71ffxY4AxwH4oBPATcB+4LxBkRERGRl+XsZ4kE8dz8cmtf+APAj75/zgM1zvhcDfBXIB8aB\nY8Aea+3L/g5WREREQs/f5yxc9O4Ja+0D877+CvAVP8clIiIiYUJrQ4iIiIhPCgsiIiLik8KCiIiI\n+KSwICIiIj4pLIiIiIhPCgsiIiLik8KCiIiI+KSwICIiIj4pLIiIiIhPCgsiIiLik8KCiIiI+KSw\nICIiIj4pLIiIiIhPCgsiIiLik8KCiIiI+KSwICIiIj4pLIiIiIhPCgsiIiLik8KCiIiI+KSwICIi\nIj4pLIiIiIhPCgsiIiLik8KCiIiI+KSwICIiIj4pLIiIiIhPCgsiIiLik8KCiIiI+KSwICIiIj75\nFRaMMb9njHnDGDNsjOk2xvybMaZsCdu9zxhTY4yZNMY0GGPuD3zIIiIiEkr+VhauB/4KeC+wF4gG\nnjXGxC+2gTGmGPgp8DywG/g68F1jzL4AxisiIiIhFuVPZ2vtB+Z+bYz5JNADVAGvLLLZQ0CTtfbz\n3q/rjTHXAfuB5/warYiIiITccucspAIWGPDR5yrg4Ly2Z4Crl3lsERERCYGAw4IxxgB/AbxirT3h\no2su0D2vrRtIMcbEBnp8ERERCQ2/LkPM8w1gJ3BtkMbyLvv378fhcFzQVl1dTXV19UodUkREZM04\ncOAABw4cuKDN6XQG/TjGWuv/Rsb8NfAh4HprbetF+r4E1FhrPzen7ZPA16y1aYtsUwnU1NTUUFlZ\n6ff4RERENqra2lqqqqoAqqy1tcHYp9+XIbxB4cPATRcLCl6HgT3z2m7xtouIiEiY8/c5C98A7gXu\nAcaMMTneV9ycPl8yxvxwzmbfAkqMMU8aY7YbYx4G7gT+PAjjFxERkRXmb2XhQSAFOAScnfO6e06f\nPGDzuS+stc3AB/E8l+Eonlsmf8NaO/8OCREREQlD/j5n4aLhwlr7wAJtL+N5FoOIiIisMVobQkRE\nRHxSWBARERGfFBZERETEJ4UFERER8UlhQURERHxSWBARERGfFBZERETEJ4UFERER8UlhQURERHxS\nWBARERGfFBZERETEJ4UFERER8UlhQURERHxSWBARERGfFBZERETEJ4UFERER8UlhQURERHxSWBAR\nERGfFBZERETEJ4UFERER8UlhQURERHxSWBARERGfFBZERETEJ4UFERER8UlhQURERHxSWBARERGf\nFBZERETEJ4UFERER8cnvsGCMud4Y85QxpsMY4zbG3H6R/jd6+819zRpjsgMftoiIiIRKIJWFROAo\n8DBgl7iNBbYBud5XnrW2J4Bji4iISIhF+buBtfZp4GkAY4zxY9Nea+2wv8cTERGR1RWqOQsGOGqM\nOWuMedYYc02IjisiIiLLFIqw0Al8GvgY8FGgDThkjLksBMcWERGRZfL7MoS/rLUNQMOcpiPGmFJg\nP3C/r23379+Pw+G4oK26uprq6uqgj1NERGStOXDgAAcOHLigzel0Bv04xtqlzlFcYGNj3MBHrLVP\n+bndl4FrrbXXLvL9SqCmpqaGysrKgMcnIiKy0dTW1lJVVQVQZa2tDcY+V+s5C5fhuTwhIiIiYc7v\nyxDGmERgK55JiwAlxpjdwIC1ts0Y8wSQb62939v/s8AZ4DgQB3wKuAnYF4Txi4iIyAoLZM7Ce4AX\n8Tw7wQJf9bb/EPh1PM9R2Dynf4y3Tz4wDhwD9lhrXw5wzCIiIhJCgTxn4SV8XL6w1j4w7+uvAF/x\nf2giIiISDrQ2hIiIiPiksCAiIiI+KSyIiIiITwoLIiIi4pPCgoiIiPiksCAiIiI+KSyIiIiITwoL\nIiIi4pPCgoiIiPiksCAiIiI+KSyIiIiITwoLIiIi4pPCgoiIiPiksCAiIiI+KSyIiIiITwoLIiIi\n4pPCgoiIiPiksCAiIiI+KSyIiIiITwoLIiIi4pPCgoiIiPiksCAiIiI+KSyIiIiITwoLIiIi4pPC\ngoiIiPiksCAiIiI+KSyIiIiITwoLIiIi4pPfYcEYc70x5iljTIcxxm2MuX0J27zPGFNjjJk0xjQY\nY+4PbLgiIiISaoFUFhKBo8DDgL1YZ2NMMfBT4HlgN/B14LvGmH0BHFtERERCLMrfDay1TwNPAxhj\nzBI2eQhostZ+3vt1vTHmOmA/8Jy/xxcREZHQCsWchauAg/PangGuDsGxRUREZJn8riwEIBfontfW\nDaQYY2Ktta7FNjz8wf28kZVHa1YCD377jygsLVrRgYqIiKw1v/253+W1ulP0RE4zEDfG2FRH0I8R\nirAQsCdpILPzBMlNExwt+3vcNpY9CZvZnVlGU0q8QoSIiGwY80PBePIgsz2n4NTwO52mEjDjkUE/\ndijCQheQM68tBxj2VVUAaP8fn6PtPVcAYNyW/N4hZpvb6TpTT0VrE7c3HyNxdyV90xl0J+XRkZzq\nCRGZCTz4HYUIERFZexYMBRkd4Oj2XNh3R8JAIdGDuTiiryGzNI50dxRNl1YyetMm0psaaf/M/xvU\nMYUiLBwGbpvXdou33adf3LyH7C1beO7kSV7t6ODYqJNjmQkcKrmemYyPQYRnfmV2/zA7Wtq5pLmR\nXc2neX9LHdFV76VvIkUhQkREwpJfoeDU5WROeUPBJZcxcdsmNkXNsCMhnivTstmbs42q9EIiIiKo\nra2lilUOC8aYRGArcO5OiBJjzG5gwFrbZox5Asi31p57lsK3gEeMMU8C3wP2AHcCH1jK8QrS0njg\n6qt5YF77wNgYz9XV8XJbG8eGhziVEsPha65g9sO/gjvSU4JJc46xvfUsl5xpZFfLaW5qOYa96lp6\nhxPoUYgQEZEQCDQUNO+6lMnbCtgcPUtFYiLvTctjX14Z5Sm5RESE9pmKxtqLPirhwg2MuRF4kXc/\nY+GH1tpfN8Z8Hyiy1t48Z5sbgK8BO4F24IvW2r/3cYxKoKampobKykq/xjc6OckLDQ281NzM0YEB\nTs3M0B0fx0x2LrPRnmyUNDbJ9taz7Go+xa7m05S3tlLW3IljMJbexFyFCBER8duioSDZO8d/TihI\nHnWcDwUtuy5h+uZNFMXArqRkrsnYxK152ylKygxoHLW1tVRVVQFUWWtrg/He/A4LobCcsLCYqZkZ\nfn7qFIeamvhFXx8NU1N0xkQzk5PPdGw0AHGuKba1drGr+RQVLU3sbGlhW0sXGX1RDMRnK0SIiEjA\noaC1YiezezdTEhvBpUkOrsvczN687eTGO4I6vpUIC2F9N0QwxURFsWfHDvbs2HFBu9vt5s2WFg42\nNvJmbw/1ZoqnthXz/197Da6EOACipmfY2tFNRXMTFS1N7G5ppu+W9xPRbXDGZilEiIisQ4FePmiv\nKMd+oJCt8VHsTk7lhswi9uRtJzUmISTjnhqbDPo+w7qy8K2C32drThqzKRPMZriJLkoi+9oKtr//\nRmLj41Z0DG63mxOdnTzb0MCRri5Ojo3REgEzmXmMpyQCEDHrprizl4qWJiqam85fzsjtsoxFpStE\niIisAZ/93Bc4XHfa70rB2YrtmH1FlMXHUOXI5IasYm7KLSMuMnrFx9xe08gvD7zEQG0jtr2LJGc/\nmWP95E120zvbxtXMwEa5DPHNHb/N9ukK6E/HDKWf/76NcUFWLzZtCHfKKLOpLsiNJrEij+2330jW\n1pIVHd/pnh6era/nSGcnb4+M0ISb2fRcRtKSz/cp6O6novkMO1vPsLO5mbKWTvI73bhwKESIiKyC\nQENBd0UZkfuK2Z4YxxWpWezJLuWqrBKiIoL/PINzXCMTHPuHQ7S8cJTxxjZi+/pIHeknZ7yXTdOd\nZNm+831HSaQ1uoCuuGwGktKpi4P/debfYaOEhblzFrpOnuLUf/6cseOd0DVN5FAsEc4kzGAa9GZh\npmPOb2/TBiC9H3fq8LuqEjs+eDMxMSuT+rqcTp49eZJX2ts55nRyenaa6bQchtNTsN6Zq9n9Tipa\nzrCz5Qw7W1rY3nyWvM5Z3DNJnFWIEBFZtkBDQU/FNmJv2cLOpESuTMthb842LksrWLE7D3xVBwpm\nO4hlyjNcDGcj8jgbk0tvYibOlAxmc7JIqSih7MNXUfb+9xAZ/U5w0QTHRbgmJql/+iV6Xj3OTMsI\nEf2RRDrjiXA6wqIqMTQ+zsGTJ3m5tZW3Bgepn3Yx7cjGmeFgNsp7m+fwKOUtLZ4g0dxMWWsnm87O\nEDkRpxAhIrKAQENBX8VWEm4tZVdyElen57Mvt4ztjtygj2851YGJtEyiivPIv7aC3fftIbUwa8nH\nVVgIULhWJcZdLg41NvJSczO1/f3UTY4zlZTJUFYa0zGeuaeJ45PnQ0R5SwvbWzrZdHaa2LFouhId\nChEisu4FGgoGdm0l+datXJqSwrUZBezL3U5hUrrvg/lppaoDy6GwsALCsSoxNTPDa01NHGpq4s3e\nXo6Pj+KKT2coO43JOE+wiXNNUdbWRkVLszdEnGXT2WkShyPpiU9WiBCRNSfQUDB0SSnp7y9jd0oq\n12cWsi9vO5lxyb4PtkSrVR1YDoWFVRBOVQm3201tWxsHGxt5o7ubX44OMx7jwJmVxlhSPABRM7Ns\na++gvLWZnc3N3hAxRcqQoT82SSFCRFZd4KGghLwPlnN5Svr52xGTopd/Z1w4VgeWQ2EhzIRTVaKu\ns5Nn6+t5vauLo0MDjEalMJyZhjPVc5uncbvZ0tl9fmJlWctZNp91kdpvGYpOUIgQkaALNBQMX7qF\nzb+yiypHJu/L2sL1OVuXdTviWqwOLIfCwhoTDlWJlr4+nqmv5/DZs9QM9DJCIiOZafRnpJzvU9DT\ny845lzM2d0yS1u9mzMR6Q0Q8D37njxUiRGRBgYaC0UuLKfnQbq5Iy2ZPzlauyCgK+HbE9VYdWA6F\nhXVktasSPcPDPFdfzyttbbzR24NzNpaRjDT6MlNwR3pv8xwY9ISI1la2N3ew+ewk6X2zuGajOJMS\nT2tmHA9+508UIkQ2iMf2f4EjJ/0PBeO7i9l+eyXvTcthX14Zuxz5ft+OuNGqA8uhsLCBrFZVYnhi\ngufr63m5pYUj3Z30u6IZy0ilJ8vBjHchrtSREcpbWjzPiWjpYHPHJBn9M8y6DM3JChEia12goWBy\n9xYu+UgVV2fkc0vedkqTs/06rqoDwaGwIMDqVCUmp6d5qbGRQ2fO8FpHBz3jMJ6eSndOGi7vQlwJ\nE5OUt74TIgo7xsnom8GMW1qS4hQiRMLMY7/9eY7UN/kVCjLcUcxetoVLP3ol12UUsC9vB/kJqUs6\nnqoDoaGwIEsSyqrEzOwsR5qaeKGpiZ+3ttLlnGEsI42enDTGEmIBiJmaZntbK+Wtrexobj8fIqJG\nZ2lPiKElM46HFCJEVkygocBUllD50au4PrOQvbk7SI9LvOixVB1YfQoLsmyhqkq43W6OdXTwXEMD\nLzU309Y3yUR6Gr3ZDoYcnl84kbOzlHZ0sLOlhR0tHRR2jJHZO03s8DRn46IVIkT8FGgoiK0s4Yq7\nruOGrGJuzikjITp20WOoOhD+FBZkxYWiKlHf1cVzDQ28eOo0Z7pGmUhPpS87lb50z0NUjNtNUXe3\nJ0Q0t1PYMUZW7xTxzim6oyMVImTDe+yxz3Ok0f9QkFBVyjUfv5Gbs0u5JquEmMioBfev6sDaprAg\nq2qlqxLtg4M8d/Ikz9U30tA+gCvVEyK6M99ZiCu/t9czJ6K1g+L2EU+IGJpiwOAJEd/+Ewq3KkTI\n+hBoKEi8Yis3f+Jm9uZsoyq98F13Hqg6sL4pLEhYW6mqRN/ICM/X1/N03UnqmnpxORz0Z6fSme1g\nxrsQV+bQEOUtLexoafeGCBeJgy6cbjetmXF8+lt/RHHZlpCfE5GlCDQUJF+5jduqb2FfXhnlKbkX\nhAJVBzbTQP9fAAAcI0lEQVQuhQVZs1aiKjE6OckLDQ3819vHOVbXwVSqg/6sVDpyU5nyho2U0VHP\nxMqWdorbh8numSRp0MXo9DRtGQoRElqBhoLUq8r4yL0f4Na87RQlZQKqDsjiFBZk3QpmVYIIw89P\nneJnx37Jm0fPMO1wMJjloC0vjYl4z8St+MlJdpwLER3D5HRPkDjkwjUxRXt6jEKELEugoSDr6u3c\n9au3szdvO7nxDlUHJCAKC7IhBasqse1Xrqc5OpJ/r32Lw2+cZDolhcEsB+15aQwnJwAQPT1NWXs7\nO1ra2dI+RE73BEmDLqbHJzmbGq0QIRd49LHHeb3xjN+hoOCacj5+/x1cl1RI67++oeqABJXCgsgC\nlluViCpKYuaSIt5IjuLlw28zm+xgKMtBR24qfWmeOzQiZmcpPXuWHa3tbGkbIqdngpSBSWZGx+lO\niVKIWOcefexxXm84Q0+Uf6Fgy/UV3H7l1SQ83czwfzepOiAhobAg4qflViVcWZE0Z8TysmuEwYwM\nnJkOzuam0pn1zhPrCru6KG9pY0v7ELnd46QMTOAeGacvMUIhYo159LHHOdJwhl4/QkGmO4rtublc\n6XIQX99PXF+/qgOyqhQWRIIs0KrETMoEQ44ZzsZNUZ+RzFtbsjibn0Z7dtr5hbhy+/u9IWKQ/K4x\nkgcmYGSc/ljLQwoRqyqQUJA9HcVlY3FUDlrSBoZUHZCwpbAgEkKBViWmU8YYS5qgL8XQmJvIi+W5\nHNuWy7R3Ia50p5Mdre2UtvWT3zVGysAEDI/hjJpViAiyRx99nCON/oWCTa4obmod54r+CXLH+lQd\nkDVHYUEkjPhflRhgJnWYyeRJ+lMtp3ITeOGSfA7vyIYIQ9L4ODta2jwhonuM1P5xzPAoI2aGh7/5\nvxQifHj0kcc5ctqPUOCKo3jScPfxbt430KnqgKwrCgsia0QgVQl3qhOXY4LBNDen8xP475JUXtmR\nyWi8oaytna1tfeR3jZHaP0bE8Bjj7ike+cYfbqgQ4W8oyHLFsXXczW+/9Uv2Os+c34+qA7KehU1Y\nMMY8AvwOkAu8BTxqrX1zkb43Ai/Oa7ZAnrW2Z5FtFBZkXfO3KmHTB5hOHcOZPktHTjQNmxL47+Jk\nhmMmKDnbT0HnCGl9Y0QMjzI5O8mjf722Q8RnHn6c15v8CQWxlI9P8wdHX6NqeEjVAdnQViIsLLyK\niA/GmI8DXwV+C3gD2A88Y4wps3bOhb0LWaAMGDnfsEhQENkIcndsJXfH1gW/t1hVImbIQdbpdLKH\n0rkc+DjnqhJRzKTFM5bmoi8D2nJj+NMf/CcDUS5SneOk9Y8RNTSKa2acz/7lH4RViHj44cd5c6FQ\nkNMNOVwQChynLifLFcvOcRe/f/QI24d7aI2OoSsuioGkWCbS8mi47jOMeqsDBYVZFKz2GxRZJ/yu\nLBhjjgCvW2s/6/3aAG3AX1prv7xA/xuBF4A0a+3wEo+hyoLIIvytSrgzBnGljTOcPsuAY5ahxGmG\no6aYnHARNTLK9PQ4+7/2P1c0RDz40OeoOdPqV6Vg57iL33yriUxXkqoDIn5Y9cqCMSYaqAK+dK7N\nWmuNMQeBq31tChw1xsQBbwN/bK19LYDximx4gVQl4gccxDdmkDuUdr6vjXFhs/qYSRvmrd/4PxxO\ncjGW4GIkykX39ASjM+Ps//LjlC5yrIV86qH9HD3T9u5QkNvtuWi5QKVg67ibD510khGZ9s7cges1\nd0AknPh7GSITiAS657V3A9sX2aYT+DTwCyAW+BRwyBhzpbX2qJ/HFxEfYuPjuPSOW+GOWxf8/tyq\nxGzHFNHDMUQNO0hpyiZlgapE84de4pTjZ7iSJnAlTDASPU6HGaEucprTo066o5caCuIonoTrOtwU\nZRR7qgMfV3VAZK3we86Cv6y1DUDDnKYjxphSPHMd7ve17eN/9dek5eau5PBENqZs74spYBTowM7O\nEjfkIrnPkjEcT8ZgOmdMJ7VpXXTEjl/08oHj1OVkTsWROxNFKpHEZWcyk52A2fzOr5mj3hd0w2v/\n7nmJSFANdnUFfZ/+hoU+YBbP1KO5cgB/RvcGcO3FOr1QWwNJSRc23nwz7Nnjx6FE5GJKX3yZlKN1\nDMx6Q8HmQWYv8xUK4sl3O7hs+AZ2n91C/lmImX5nf30Z0JnneZ3Nv/C//Rl4LkyKyPI9/zy88MKF\nbaOjQT9MsCY4tuKZ4PiVJe7jWWDYWnvnIt+vBGpu/uQDqiyIBMhOzxDZP0n80CRJo1OkTbjoZIyT\nidF0RM8s+YmG6TaShJwU0vIW/rs45Zqiu7WdnKgksmeTyRhLIn00idThRFKHkkkeTCVh2HG+/0z0\nFKPpAww7hhhOGWYoeZTBpAmGUqYZyYrGHRcditMjsm4NdnXxwg++D6v5nAVjzN3AD4AHeefWyTuB\nHdbaXmPME0C+tfZ+b//PAmeA40AcnjkLjwD7rLWHFjmG7oYQWYL2mkZ+eeAlBmobL1jR8NU8+K+i\nbFrioH+JoSDLRvHp6o/xq7/2iaCMra+rly/+5h8SHRVHdGICKZGxpEzFkjIWRYozioTBOKIHkpe0\nMmh0URLZ11aw44M3ExOjMCHiy6rfDQFgrf1nY0wm8EU8lx+OArdaa3u9XXKBzXM2icHzXIZ8YBw4\nBuyx1r68nIGLbASukQmO/cMhWl44ynhjG7F9fResaPhfJVn8pHgbLQnQf+nS5hRk2ygevvcuqu+7\ne0XHnpmbxV/+9Fvvau/r6uVPH/h9YlLimNmdxGB6HNEx8aRNxpA7ZMjtnSVlIIrYwVSiT5cQ472D\nY+Cr8GrMC+9aGZTcaBIr8th++41kbS1Z0fckslHpcc8iq2yx6sDcFQ2/U1rOT4q30RzH0ldJDFEo\nCJa+rl6euP/3iI2IZTY1icGMRM7mJjGQ6iBvOJqKtjGKulxk9VkSBmOJHHSoKiGygLB53PNKU1iQ\n9eRi1YG5Kxr+Teml/OOWEtpi3X6Fgkfuu5tP3HvX6rzBFdbX1cuTv/a7xBPDrCMRZ3oCZ3OTOFWY\nyem8fMrPjnPFqUF2to6wqXuapKFoopxJmP4MzLznSqgqIRuBwoJImFpKdQDeWdHwO1vLOFiYTkfs\n0icaZtsoHvnVu/nEPeszFPirr6uXL//qF0icjcKmJOLM8ISIpoJ06ooLGYuPJ3twghuPd3NlYz+F\n3S6Sh6OIGU4kYjBVVQlZtxQWRFaJP9WB8ysaxmfxfwpTeTMvls6YJS6drFCwbH1dvXzlvs+TMh0J\nKYk40+Ppyknk9OZ06oo2M5iSAkDcxBT7/ruVq071U9g3SepIJHHDCUQ6UxZdGVRVCVkLFBZEVpC/\n1YGzMbn0JGbSn+bg+QxLvcO++4mGCgVhwxMivkD6hIWURIbT4+nKSaCpIJ2TRQV0ZWQAEDHrpqBn\nkJ2nu6lq6ad4cILM0VgSR2KJ9LEGh6oSEi4UFkSWIaDqQFw2A0npjGVk4Nzi4MWpXtqZWPKCSAoF\n4a+vq5c/u+8LZI7OYpITGE2LpzMngTObUzlZWEDrnGe95PUOsalzEEfvENu6+9k9G03BEMQMetbg\niHA6VJWQVaewIHIRgVQH5q5oGFOxmf4bc3jqmUP09zkVCjawcyEiZ2iKSG+I6MqJp7nAQV3RZpry\n8nBHeta1yBwcoaBzEEefkyinkyuLcnjv8CyxTf2Y7pmLrgyqqoQEk8KCbHjLqQ6cX9Hw2gqyPno5\nr0b08a//z/cY6FUokKU7FyLyB1xEJ8YzmhZHd3acJ0QUb6Zx0yamoz0f8I6RcQo6B0nr9YSIyy4t\n4o7Ky3HUNdN7uO6ClUFVlZBgUViQDWG51YGUihLKPuxZ0bBhrIdnztbzsy/9iKG+YYUCWTEDPf18\n+Z7HKeibJDY+lrG0OHqyYzlT4KC+cBN1RUVMxsYCkDDhoqBzkPTeIaKdw1Rsz+Ouq67kutJSBk41\nn18ZlK5pVSXEbwoLsi4Eqzqw+749pBZm4Xa7qR1o47nOBp5/8gDOQELBr32cT1QvuFSJyLKcCxGb\neydIiI1mwhHrrUSkUF+0iRNFRYwkJgIQMzVNQdcg6b1OYoaclG3J4I73VHFzWRlJcXG4Jiapf/ol\nel49rqqELEphQdaMYFYHIqM914Vn3LO81nOa57tO8/M/+xdGFApkDTsXIgp7xkmJjGQ8NZbe7Fha\nNiVzsmgTJ4qL6Xd4FuCKmpklv3uI9F4nsUNDlGxy8OHLd7OvvJx0b9AA6Dp5SlUJUViQ8BHs6sBc\n49MuDvU0cqj7DG/8+b8xplAgG8i5EFHUM04ahglHDL3ZMbRuSuJkUQF1hYWczfL8nTFuN7l9w2T2\nDBE7OMTmrAQ+tPsSbi0vJz819YL9qiqxcSgsSEitRHVgrqGpcQ52nuSlnhaO/cV/MN6vUCCymLkh\nImvGMumIpj8zmpaCJE4WeeZENOflne+f2T9CVs8gcYNONqVHc1tFBfvKytiWk7Pg/lWVWD8UFiSo\nVrI6MFfXhJNnO0/y8942Tn79Z0wOjPgdCh59oJq77/7oCp8RkbVnbojIc80wlRxNX1Y0rQWJ1Bfm\nc6KoiNObNjHrvc0z1TlGVs8QCQND5DmiuHnbVvaVlXHppk1EREQseAxVJdYWhQXx20pXB+Y6M9LL\ns131vNrbwZm/fobJAf8rBQoFIsExN0RsmphmNjGS/qwo2vITOFnsmVjZULCZKW8VIGlskuyeIRL6\nh8hJMtywpZg9paW8d8sWoiJ9/91XVSK8KCzIu4SqOnCO2+3mhLOTZ7saeL2vk7ZvPse0KgUia8bc\nEFE45sLGR9CfGUn7pgROFuVTV1REXWER4/FxAMS6psnpHiSxf4jsBMs1BQXcVFLC9Vu3Ehd98Q92\nVSVCT2FhgwpldeAct9vNm/0tHOxu5I2+bnq//YJCgcg6NjdEFI1OEhkDgxkRtG2K52TxJuoKCzlR\nXIwzKQmA6OkZsnucJA4MkRkzw3tzc7m+qIg927eTEh+/5OOqKhF8CgvrVKirA3NNzc7wSs9pXuw5\nzZsDvTi/8xIzunwgIl5zQ0TxyCRxETMMZEbStimOhiLPnIgTRcX0pnnuvoiYdZPZN0xy/yDpUVNU\nZWZx3ebN3LpjB5nJyX4dW1WJwCgsrGGrUR2Ya3R6khe6Gvh5bws1g31MfPfnzAz6Hwoe+/V7uOuu\nO4J5akRkDZobIraMTJJopxjKMLTnx1LvDRF1RcW0Z5+7zdOSPjhCSt8gKUxweXoG127axC07dlCY\nnn6Roy1MVYmFKSyEsdWsDsw1MDnGc111vNzXxltDg0z/3Su4FQpEJETmh4jU6Qmc6XhCRHG+53JG\n0RbO5OVgvXdfOIZGcfQNkTQ7ym5HKlfn5bG3rIzyObeC+msjVyUUFlbZalcHLhjL2CDPdZ3k1b4O\njjmd2O+9CkN+hgKieOwBhQIRWXnzQ0TG5BgjqW46NsVSX5RHnfdyxqlNm5iJ8vx+TBqdwNE3SILL\nySVJKVyRk8Pebduo3Lx50ds8l2o9VyUUFlZYuFQH5mp0dvNMVz1HBjp52zlK9A8UCkRk/ZgfInLG\nRxhLmaUjP5qGojxOFBVxvHgLDZs34/J+KMdNuEjtHSJ+YpDyhESuyMri5pISriktvehtnkux1qsS\nCgtBEE7VgXPcbjfHhjp4rquBNwa7OTE8TsKPDsOgn0snE81jD1QrFIjImjc/ROSNOplMmqYzL4r6\nojxOFBdzorCYE8Xv3OYZPTVNat8QcaP9bI+NpzIjgxuLi3nftm0keFf8DIZwr0ooLCxBOFYHzplx\nz/J63xme7z7Nm0M91I+4SPnRYcyQQoGIyFLMDxGbhoeYiZ+kMz/q/OWM40VbOFFczFCyZ5GtyJlZ\nUvudxDh72RYdw2VpaVxfWMjeHTtITUgI6vjCoSqhsOAVjtWBuSZnp3mpu5GXes5Q4+yjYXSajL8/\nghkaUigQEVkBC4WIiKhRT4gozqOusNATIoq20JPhWc3TuN2kDAwTM9hDaWQUlzgcXFdQwC07dpDr\nXfEz2EJRldhwYeHJfY+Q2+cOq+rAXMNTEzzfVc/LvS0cHRnk1NgMOQoFIiJhY36IKBgeIsY46cyL\npLEwhxPFxedDRHtOxvntkgdHiB7oopgIdiUnc01+Prds386WrJX7TAlWVcJVmsHej3wYNkpYqAEu\nW6XqwFx9kyM803mSV/raODYyRNO4JfcnR4gaHFQoEBFZgxYKEYmzA3TlGhqLcr0Pm9rC28UltORm\n4Y703H2RMDxGTF83m91udiYmcmVuLreUlbEzL2/Zd2hczFKrEg008Gk+DRslLHz74S9x1xd+c0Wr\nA3O1jg7wbNdJXu3v4Jejw7ROGDb9w2GiBhQKREQ2goVChMPVS2+OpaEo1zsnooS3t5RyOj+bmego\nAOLGJ4np7SZ/epod8fG8JyuLvdu2cUVR0YqHCLiwKnHyaD2PPv9t2ChhYaVunawb6uTZrnpeH+zi\n+Ngo7RORbD5whOiB/g0dCg4cOEB1dfVqD2ND0TkPPZ3z0FsP53yhEJE+0c1A5iwNxbnUFRbydnEp\nx4tKaSjMwxXrmU8Q7Zoipreb3EkX22JieE9mJjeVlnJdaSkxUVErMtawmbNgjHkE+B0gF3gLeNRa\n+6aP/u8DvgpUAK3An1prf+ij/7LDgtvtpnagjYPdjbw51E3d+AQdk9FsOXCY6IG+DR0KFnP77bfz\n1FNPrfYwNhSd89DTOQ+99XzOB3r6+co9j1M4J0RkjncxnDZFY1EOJ4qKeLuohOPFWzlZlM9Yguc2\nz8jpGWJ6u8kan2BrVBSVGRlcX1TEzWVlJMXFLWtMKxEW/I41xpiP4/ng/y3gDWA/8IwxpszaOTMP\n3+lfDPwU+AZwD7AX+K4x5qy19rnAh+4x457llZ7THOpp4s2hXhonXZx1xbD1wBGiB3reFQre2v7u\nUOA4dfn5UPDZB6q5c52HAhERCY707AyeOPi9d7XH9PTz/Xsep/DEONWvn6Bg+DWyRzuZSBmnocg7\nsbJwC7/cso3aoixeSE7kzwYGiHj1VaJ7e8gYHaMkMpJLU1O5YfNm9pWXk56YuArv0COQGsh+4G+t\ntT8CMMY8CHwQ+HXgywv0fwhostZ+3vt1vTHmOu9+lhwWxqddHOpp5KWeZmqH+2mcnKbHFU/ZP75G\n9EC3QoGIiISNxULEQE8/L9zzOIUN43y0ppHHht8kZ7STmXgnDcWeiZXHi0r45ZYyThZm80paCt8Y\nHYXX3yC6v4+04WGKjeGSlBSu3bSJW8vLyU9NXfH341dYMMZEA1XAl861WWutMeYgcPUim10FHJzX\n9gzwtYsd7zfffIqe3lr6ppLYceDnCgUiIrKm+QoRT9/zOIVnxvmVY2d4cPi/yRntxEQP0FiUTV1R\nEW8XlXJsSxkniwp4IzONv3O54OhRIgcGSB0aYrO1VCQlUTAyEvRx+1tZyAQige557d3A9kW2yV2k\nf4oxJtZa61pgmziAur/7F6Zy3bgdPbyVPADJgI0AZy5R3RmknCkhdbqcdKKovv1W9n745gUHUFsb\nlEs2657T6dS5CjGd89DTOQ89nfOluevLnzn/5ymgDXAODPGj//kX5DZOUnL0l1w19hoZ431ERQzQ\nnpPGmbw8TuUXcCq/mKa8HN7KnMa2t5/bzfImP8zh1wRHY0we0AFcba19fU77k8AN1tp3VReMMfXA\n96y1T85puw3PPIaEhcKCMeYe4Cf+vBERERG5wL3W2n8Ixo78rSz0AbNAzrz2HKBrkW26Fuk/vEhV\nATyXKe4FmoFJP8coIiKykcUBxXg+S4PCr7BgrZ02xtQAe4CnAIwxxvv1Xy6y2WHgtnltt3jbFztO\nPxCUNCQiIrIBvRbMnQXyWKk/Bz5ljPk1Y8wO4FtAAvADAGPME8aYuc9Q+BZQYox50hiz3RjzMHCn\ndz8iIiIS5vy+ddJa+8/GmEzgi3guJxwFbrXW9nq75AKb5/RvNsZ8EM/dD48B7cBvWGvn3yEhIiIi\nYSgsH/csIiIi4WPlV7cQERGRNU1hQURERHxalbBgjHnEGHPGGDNhjDlijLniIv3fZ4ypMcZMGmMa\njDH3h2qs64U/59wYc4cx5lljTI8xxmmMec0Yc0sox7se+PtzPme7a40x08YYPcXGTwH8bokxxvyp\nMabZ+/ulyRjzyRANd10I4Jzfa4w5aowZM8acNcb8nTEmPVTjXeuMMdcbY54yxnQYY9zGmNuXsM2y\nP0NDHhbmLET1R8DleFatfMY7aXKh/sV4HuD0PLAb+Dqehaj2hWK864G/5xy4AXgWzy2vlcCLwH8Y\nY3aHYLjrQgDn/Nx2DuCHvPsR6XIRAZ7zfwFuAh4AyoBqoH6Fh7puBPD7/Fo8P9/fAXbiuTPuSuDb\nIRnw+pCI58aCh4GLTjoM2meotTakL+AI8PU5Xxs8d0h8fpH+TwLH5rUdAP4z1GNfqy9/z/ki+3gb\n+IPVfi9r5RXoOff+bP8Jnl++tav9PtbSK4DfLe8HBoDU1R77Wn0FcM7/B9A4r+0zQOtqv5e1+ALc\nwO0X6ROUz9CQVhbmLET1/Lk26xl5IAtRLdZf5gjwnM/fh8GzMsfASoxxvQn0nBtjHgC24AkL4ocA\nz/mHgF8AXzDGtBtj6o0xXzHGBO15+utZgOf8MLDZ+8h/jDE5wF3Az1Z2tBtaUD5DQ30ZwtdCVLmL\nbONzIargDm9dCuScz/c4ntLXPwdxXOuZ3+fcGLMNz2qu91pr3Ss7vHUpkJ/zEuB6oAL4CPBZPGXx\nv1mhMa43fp9za+1rwH3APxljpoBOYBBPdUFWRlA+Q3U3hPjkXdTrD4G7rLV9qz2e9cgYE4Fn4bQ/\nstaePte8ikPaKCLwlHHvsdb+wlr7NPA54H79Q2RlGGN24rlm/sd45kPdiqea9rerOCxZAr+f4LhM\noVqISt4RyDkHwBjzCTwTj+601r64MsNbl/w958nAe4DLjDHn/lUbgecK0BRwi7X20AqNdb0I5Oe8\nE+iw1o7OaavDE9QKgNMLbiXnBHLOfxd41Vp77nH/b3uXAPi5Meb3rbXz/wUsyxeUz9CQVhastdPA\nuYWogAsWolps0YvDc/t7+VyISt4R4DnHGFMN/B3wCe+/uGSJAjjnw8Au4DI8s5V341lT5aT3z68v\nsI3MEeDP+atAvjEmYU7bdjzVhvYVGuq6EeA5TwBm5rW58czqVzVtZQTnM3QVZm/eDYwDvwbswFN+\n6geyvN9/AvjhnP7FwAieGZ3b8dwuMgXsXe2ZqGvlFcA5v8d7jh/Ek0DPvVJW+72slZe/53yB7XU3\nxAqfczzzcFqAfwLK8dwyXA98a7Xfy1p5BXDO7wdc3t8tW4BrgTeA11b7vayVl/fndjeef1y4gd/2\nfr15kXMelM/Q1XqzDwPNwASedPOeOd/7PvDCvP434EmwE0Aj8Kur/T9srb38Oed4nqswu8Dre6v9\nPtbSy9+f83nbKiyE4JzjebbCM8CoNzh8GYhd7fexll4BnPNHgF96z3k7nucu5K32+1grL+BGb0hY\n8PfzSn2GaiEpERER8Ul3Q4iIiIhPCgsiIiLik8KCiIiI+KSwICIiIj4pLIiIiIhPCgsiIiLik8KC\niIiI+KSwICIiIj4pLIiIiIhPCgsiIiLik8KCiIiI+PR/AZVZqFj9eon3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x97d8080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert your code here\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([2.795, 3.795])\n",
    "plt.plot([3.795, 2.795])\n",
    "plt.plot([3.105, 3.105])\n",
    "plt.plot([3.667, 3.667])\n",
    "\n",
    "for b in unique_belief_list:\n",
    "    plt.plot(b[0])\n",
    "\n",
    "plt.axis([0, 1, 0, 4])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5]]\n",
      "[ 0.5]\n",
      "[ 0.5]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[0.5, 0.5]])\n",
    "b = np.array([[0.9, 0.1]])\n",
    "c = np.array([[0.988, 0.012]])\n",
    "#[array([[ 0.5,  0.5]]), array([[ 0.9,  0.1]]), array([[ 0.988,  0.012]])]\n",
    "list = [a, b, c]\n",
    "print a\n",
    "print a[:,0]\n",
    "print a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-5cdd4542d8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "\n",
    "print a/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [1 0 0]]\n",
      "[[ 0.5  0.5]]\n",
      "[[ 0.5  0.5  0. ]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[0.5, 0.5]])\n",
    "\n",
    "OP = np.array([[0, 1, 0], [1, 0, 0]])\n",
    "\n",
    "\n",
    "print OP\n",
    "print B\n",
    "\n",
    "print B.dot(OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
