{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Laboratory 4: Partially observable Markov decision problems\n",
    "\n",
    "In the end of the lab, you should submit all code/answers written in the tasks marked as \"Activity n. XXX\", together with the corresponding outputs and any replies to specific questions posed to the e-mail <adi.tecnico@gmail.com>. Make sure that the subject is of the form [&lt;group n.&gt;] LAB &lt;lab n.&gt;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Modeling\n",
    "\n",
    "Consider once again the guessing game domain described in the Homework and which you described as a POMDP.\n",
    "\n",
    "Recall that:\n",
    "\n",
    "* The opponent can hold one of two cards in hand: an Ace of Clubs (A&clubs;) and an Ace of Diamonds (A&diams;). The agent must guess which card the opponent is holding. \n",
    "\n",
    "* For every right answer, the agent wins 1EUR, and every wrong answer costs the agent 1EUR. \n",
    "\n",
    "* The agent can also try to _peek_. \n",
    "\n",
    "* When the agent peeks, it sees the right card with a probability of 0.9 and the wrong card with probability 0.1.\n",
    "\n",
    "* The game restarts whenever the agent makes a guess.\n",
    "\n",
    "Consider throughout that $\\gamma=0.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Implement your POMDP in Python. In particular,\n",
    "\n",
    "* Create a list with all the states;\n",
    "* Create a list with all the actions;\n",
    "* Create a list with all the observations\n",
    "* For each action, define a `numpy` array with the corresponding transition probabilities;\n",
    "* For each action, define a `numpy` array with the corresponding observation probabilities;\n",
    "* Define a `numpy`array with the cost that you defined in your homework.\n",
    "\n",
    "The order for the states and actions used in the transition probability and cost matrices should match that in the lists of states and actions. \n",
    "\n",
    "**Note**: Don't forget to import `numpy`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "import numpy as np\n",
    "\n",
    "states = [\"Clubs\" , \"Diamonds\"]\n",
    "\n",
    "actions = [\"SelectClubs\", \"SelectDiamonds\", \"Peek\"]\n",
    "\n",
    "observations = [\"Clubs\", \"Diamonds\"]\n",
    "\n",
    "P_Peek = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "P_Clubs = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "P_Diamonds = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "\n",
    "O_Peek = np.array([[0.9, 0.1], [0.1, 0.9]])\n",
    "\n",
    "O_Clubs = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "O_Diamonds = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "Cost = np.array([[0, 1, 0.5], [1, 0, 0.5]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Sampling\n",
    "\n",
    "You are now going to sample random trajectories of your POMDP and observe the impact it has on the corresponding belief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "raw_mimetype": "text/latex"
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 2.\n",
    "\n",
    "Generate a random POMDP trajectory using a uniformly random policy. In particular, from a random initial state $x_0$ generate:\n",
    "\n",
    "1. A sequence of 10,000 states by selecting the actions uniformly at random;\n",
    "2. The corresponding sequence of 10,000 actions;\n",
    "3. The corresponding sequence of 10,000 observations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "t = 0\n",
    "\n",
    "initial_policy = np.array([[1./3, 1./3, 1./3], [1./3, 1./3, 1./3]])\n",
    "\n",
    "sequence_states = []\n",
    "sequence_actions = []\n",
    "sequence_observations = []\n",
    "\n",
    "\n",
    "# DUVIDA: depois de fazermos peek e observarmos algo \n",
    "# temos de actualizar de novo a observacao quando o oponente mostra que carta tem ?\n",
    "\n",
    "while t<10000:\n",
    "    \n",
    "    state = np.random.choice(states,1, replace=False)\n",
    "    action = np.random.choice(actions,1, replace=False)\n",
    "    \n",
    "    if state == \"Clubs\":\n",
    "        observation_probabilities = O_Peek[:,0] # [0.9]\n",
    "                                                # [0.1]\n",
    "    else:\n",
    "        observation_probabilities = O_Peek[:,1] # [0.1]\n",
    "                                                # [0.9]\n",
    "    if action == \"Peek\":\n",
    "        observation = np.random.choice(observations,1, replace=False, p=observation_probabilities)\n",
    "    else:\n",
    "        # V1\n",
    "        observation = state # se a accao for adivinhar uma carta a nossa observacao\n",
    "                            # vai ser igual ao estado (que e a carta que esta na mao do oponente)\n",
    "        # V2\n",
    "        #observation = np.random.choice(observations,1, replace=False, p=np.array([0.5, 0.5]))\n",
    "\n",
    "    sequence_states += [state]\n",
    "    sequence_actions += [action]\n",
    "    sequence_observations += [observation]\n",
    "    t+=1\n",
    "    \n",
    "    \n",
    "#print \"STATES(carta que esta na mao do oponente)\\n\"\n",
    "#for i in sequence_states:\n",
    "#    print i\n",
    "#print \"\\nACTIONS(accao que o agente escolhe)\\n\"    \n",
    "#for i in sequence_actions:\n",
    "#    print i\n",
    "#print \"\\nOBSERVATIONS(observacao que o agente faz)\\n\"\n",
    "#for i in sequence_observations:\n",
    "#    print i\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 3.\n",
    "\n",
    "For the POMDP trajectory generated in Activity 2, compute the corresponding sequence of beliefs, assuming that the initial belief is $\\mathbf{b}_0=[0.5, 0.5]$. Report the resulting beliefs, ignoring duplicate beliefs or beliefs whose distance is smaller than $10^{-4}$.\n",
    "\n",
    "**Note 1:** You may want to define a function `belief_update` that receives a belief, an action and an observation and returns the updated belief.\n",
    "\n",
    "**Note 2:** To compute the distance between vectors, you may find useful `numpy`'s function `linalg.norm`.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "initial_belief = np.array([[0.5, 0.5]])\n",
    "belief_list = [initial_belief]\n",
    "\n",
    "\n",
    "def belief_update(belief, action, observation):\n",
    "        \n",
    "    if action == \"Peek\":\n",
    "        \n",
    "        Pa = P_Peek\n",
    "        \n",
    "        if observation == \"Clubs\":\n",
    "            Diag_O = np.diag(O_Peek[:,0])\n",
    "        else:\n",
    "            Diag_O = np.diag(O_Peek[:,1])\n",
    "            \n",
    "    elif action == \"SelectClubs\" or action ==\"SelectDiamonds\":\n",
    "        \n",
    "        Pa = P_Clubs # Clubs e Diamonds tem P iguais por isso nao faz diferenca\n",
    "        \n",
    "        if observation == \"Clubs\":\n",
    "            Diag_O = np.diag(O_Peek[:,0])\n",
    "        else:\n",
    "            Diag_O = np.diag(O_Peek[:,1])\n",
    "\n",
    "    \n",
    "    aux1 = np.dot(belief, Pa * Diag_O) # belief * Pa * Diag_O\n",
    "    aux2 = aux1[:,0] + aux1[:,1] # [a, b] --> a+b\n",
    "\n",
    "    \n",
    "    updated_belief = aux1/aux2\n",
    "    \n",
    "    return updated_belief\n",
    " \n",
    "#print belief_update(initial_belief,\"Peek\",\"Diamonds\")\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "unique_belief_list = [initial_belief]\n",
    "\n",
    "\n",
    "for action, observation in zip(sequence_actions, sequence_observations):\n",
    "    \n",
    "    #print initial_belief #so para a primeira belief aparecer tambem  \n",
    "    \n",
    "    new_belief = belief_update(initial_belief,action,observation)\n",
    "    \n",
    "    initial_belief = new_belief\n",
    "  \n",
    "    # CONFIRMAR ESTA CONDICAO\n",
    "    \n",
    "    \n",
    "    #print unique_belief_list\n",
    "    #print new_belief\n",
    "    #print np.all(unique_belief_list != new_belief)\n",
    "    if np.all(unique_belief_list != new_belief) and np.linalg.norm(new_belief) >= 1e-4:\n",
    "        unique_belief_list += [new_belief]\n",
    "        \n",
    "\n",
    "\n",
    "#print \"\\nbelief list without repetitions:\"\n",
    "\n",
    "#for i in unique_belief_list:\n",
    "#    print i\n",
    "    \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Solution methods\n",
    "\n",
    "In this section you are going to compare different non-exact solution methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 4\n",
    "\n",
    "Compute the solution for the underlying MDP and report the corresponding optimal policy and optimal cost-to-go. \n",
    "\n",
    "** Note:** You may reuse code from previous labs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost to Go:\n",
      "[[ 0.]\n",
      " [ 0.]]\n",
      "Optimal Policy:\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]]\n",
      "[ 0.  1.]\n",
      "[ 1.  0.]\n",
      "[ 0.5  0.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "\n",
    "ident = np.eye(2)\n",
    "\n",
    "gamma = 0.9\n",
    "\n",
    "def calc_cost_to_go(initial_policy):\n",
    "    \n",
    "    pi = initial_policy\n",
    "    \n",
    "    # ja estao la em cima é so para me organizar melhor \n",
    "    P_Peek = np.array([[1, 0], [0, 1]])\n",
    "    P_Clubs = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "    P_Diamonds = np.array([[0.5, 0.5], [0.5, 0.5]]) \n",
    "    \n",
    "    \n",
    "    C_Peek = Cost[:,0][np.newaxis, :].T\n",
    "    C_Clubs = Cost[:,1][np.newaxis, :].T\n",
    "    C_Diamonds = Cost[:,2][np.newaxis, :].T\n",
    "\n",
    "    \n",
    "    Ppi = np.diag(pi[:,0]).dot(P_Peek) + \\\n",
    "          np.diag(pi[:,1]).dot(P_Clubs) + \\\n",
    "          np.diag(pi[:,2]).dot(P_Diamonds)\n",
    "          \n",
    "    \n",
    "    Cpi = np.diag(pi[:,0]).dot(C_Peek) + \\\n",
    "          np.diag(pi[:,1]).dot(C_Clubs) + \\\n",
    "          np.diag(pi[:,2]).dot(C_Diamonds)\n",
    "          \n",
    "                \n",
    "    \n",
    "    J = np.linalg.inv(np.eye(2) - gamma * Ppi).dot(Cpi)\n",
    "    \n",
    "    return J\n",
    "\n",
    "##########################################################\n",
    "##########################################################\n",
    "Qpeek = []\n",
    "Qclubs = []\n",
    "Qdiamonds = []\n",
    "\n",
    "policy_J_optimal = np.zeros((2,2))\n",
    "\n",
    "def calc_pol_iter():\n",
    "    \n",
    "    pi = initial_policy\n",
    "    #pi = np.array([[0, 0, 0], [0, 0, 0]])\n",
    "    \n",
    "    # ja estao la em cima é so para me organizar melhor \n",
    "    P_Peek = np.array([[1, 0], [0, 1]])\n",
    "    P_Clubs = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "    P_Diamonds = np.array([[0.5, 0.5], [0.5, 0.5]]) \n",
    "    \n",
    "    C_Peek = Cost[:,0]\n",
    "    C_Clubs = Cost[:,1]\n",
    "    C_Diamonds = Cost[:,2]\n",
    "\n",
    "    \n",
    "    quit = False \n",
    "    \n",
    "    while not quit:\n",
    "        \n",
    "\n",
    "        Ppi = np.diag(pi[:,0]).dot(P_Peek) + \\\n",
    "              np.diag(pi[:,1]).dot(P_Clubs) + \\\n",
    "              np.diag(pi[:,2]).dot(P_Diamonds)\n",
    "\n",
    "\n",
    "        Cpi = np.diag(pi[:,0]).dot(C_Peek) + \\\n",
    "              np.diag(pi[:,1]).dot(C_Clubs) + \\\n",
    "              np.diag(pi[:,2]).dot(C_Diamonds)\n",
    "                \n",
    "        J = np.linalg.inv(np.eye(2) - gamma * Ppi).dot(Cpi)\n",
    "        \n",
    "        global Qpeek\n",
    "        global Qclubs\n",
    "        global Qdiamonds\n",
    "        Qpeek = C_Peek+ gamma * P_Peek.dot(J)\n",
    "        Qclubs = C_Clubs + gamma * P_Clubs.dot(J)\n",
    "        Qdiamonds = C_Diamonds + gamma * P_Diamonds.dot(J)\n",
    "        \n",
    "        \n",
    "        pinew = np.zeros((2,3))\n",
    "        \n",
    "        \n",
    "        pinew[:,0] = np.isclose(Qpeek, np.min([Qpeek, Qclubs, Qdiamonds], axis=0), atol=1e-10, rtol=1e-10).astype(int)\n",
    "        pinew[:,1] = np.isclose(Qclubs, np.min([Qpeek, Qclubs, Qdiamonds], axis=0), atol=1e-10, rtol=1e-10).astype(int)\n",
    "        pinew[:,2] = np.isclose(Qdiamonds, np.min([Qpeek, Qclubs, Qdiamonds], axis=0), atol=1e-10, rtol=1e-10).astype(int)        \n",
    "    \n",
    "        pinew = pinew / np.sum(pinew, axis=1, keepdims = True)\n",
    "        \n",
    "        quit = (pi == pinew).all()\n",
    "        pi = pinew\n",
    "    \n",
    "    \n",
    "\n",
    "    return pi\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "#######################\n",
    "\n",
    "optimal_policy = calc_pol_iter()\n",
    "cost_to_go = calc_cost_to_go(optimal_policy)\n",
    "\n",
    "print \"Cost to Go:\"\n",
    "print cost_to_go\n",
    "print \"Optimal Policy:\"\n",
    "print optimal_policy\n",
    "\n",
    "\n",
    "print Qpeek\n",
    "print Qclubs\n",
    "print Qdiamonds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 5\n",
    "\n",
    "For each of the beliefs computed in Activity 3, compute the action prescribed by:\n",
    "\n",
    "* The MLS heuristic;\n",
    "* The AV heuristic;\n",
    "* The Q-MDP heuristic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLS Heuristic\n",
      "\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "\n",
      "AV Heuristic\n",
      "\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectDiamonds\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "\n",
      "Q-MDP Heuristic\n",
      "\n",
      "Peek\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "SelectClubs\n",
      "Peek\n",
      "Peek\n",
      "SelectClubs\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "Peek\n",
      "SelectClubs\n",
      "Peek\n",
      "Peek\n",
      "Peek\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "#Qpeek\n",
    "#Qclubs\n",
    "#Qdiamonds\n",
    "\n",
    "def MLS(belief):\n",
    "    \n",
    "    if belief[:,0]>=  b[:,1]:\n",
    "        return actions[0]\n",
    "    else:\n",
    "        return actions[1]\n",
    "   \n",
    "    \n",
    "def AV(belief):\n",
    "    \n",
    "    clubs_weight = belief[:,0]\n",
    "    diamonds_weight = belief[:,1]\n",
    "    \n",
    "    if clubs_weight >= diamonds_weight:\n",
    "        return actions[0]\n",
    "    else :\n",
    "        return actions[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "def QMDP(belief):\n",
    "    \n",
    "    actionSC = belief[:,0]* Qclubs[0] + belief[:,1]* Qclubs[1]\n",
    "    actionSD = belief[:,0]* Qdiamonds[0] + belief[:,1]* Qdiamonds[1]\n",
    "    actionP = belief[:,0]* Qpeek[0] + belief[:,1]* Qpeek[1]\n",
    "    \n",
    "    #print actionSC\n",
    "    #print actionSD\n",
    "    #print actionP\n",
    "        \n",
    "\n",
    "    if actionSC<= actionSD and  actionSC< actionP:\n",
    "        return actions[0]\n",
    "    elif actionSD< actionSC and  actionSD< actionP:\n",
    "        return actions[1]\n",
    "    else:\n",
    "        return actions[2]\n",
    "    \n",
    "\n",
    "    \n",
    "mls=[]    \n",
    "print \"\\nMLS Heuristic\\n\"\n",
    "for b in unique_belief_list:\n",
    "    aux1= MLS(b)\n",
    "    mls+=[aux1]\n",
    "    print aux1\n",
    "\n",
    "av=[]   \n",
    "print  \"\\nAV Heuristic\\n\"\n",
    "for b in unique_belief_list:\n",
    "    aux2= AV(b)\n",
    "    av+=[aux2]\n",
    "    print aux2\n",
    "    \n",
    "    \n",
    "qmdp=[]    \n",
    "print  \"\\nQ-MDP Heuristic\\n\"\n",
    "for b in unique_belief_list:\n",
    "    aux3= QMDP(b)\n",
    "    qmdp+=[aux3]\n",
    "    print aux3\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 6\n",
    "\n",
    "Suppose that the optimal cost-to-go function for the POMDP can be represented using the $\\alpha$-vectors\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{bmatrix}\n",
    "2.795\\\\\n",
    "3.795\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "3.795\\\\\n",
    "2.795\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "3.105\\\\\n",
    "3.105\n",
    "\\end{bmatrix}\\right\\}$$\n",
    "\n",
    "corresponding to the actions 'Guess clubs', 'Guess diamonds' and 'Peek', respectively. Represent the optimal cost-to-go function and compare the optimal policy with the MDP heuristics from Activity 5 in the beliefs computed in Activity 3.\n",
    "\n",
    "** Note: ** Don't forget to import `matplotlib`, and use the magic `%matplotlib notebook`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAHX5JREFUeJzt3X2QZWV94PHvD5EZYaWRl5mBOCkcRDIvu2A3JiABRN4W\nrfhKjFfYDOiyAqbCtrurSW22TKwKBClEkoi4S4xYJB3dbKViyAYQFWdViGX3jqzDACPDmwLDCNJj\neHfmt3/cO9pz6X66z+3b962/n6pbTD/3nHuePrbT3znn3HMjM5EkSZrJXt2egCRJ6m3GgiRJKjIW\nJElSkbEgSZKKjAVJklRkLEiSpCJjQZIkFRkLkiSpyFiQJElFxoIkSSqaVyxExO9FxK6I+OQsy70p\nIsYj4rmIuDci1s9nu5IkqXNajoWIeAPwH4DvzbLc4cCNwFeBo4Grgesi4vRWty1JkjqnpViIiH8F\n3AD8e+CpWRa/CNiamR/JzHsy89PA3wKjrWxbkiR1VqtHFj4N/ENmfm0Oyx4H3No0djNwfIvbliRJ\nHbR31RUi4r3AMcCxc1xlBbCtaWwbsH9ELMnM56fZxkHAmcADwHNV5yhJ0iK2FDgcuDkzn2jHC1aK\nhYh4NfAp4LTMfLEdE5jBmcBfLeDrS5I06M4B/rodL1T1yMIIcAgwERHRGHsZcFJE/A6wJDOzaZ3H\ngOVNY8uBHdMdVWh4AOCGG25g9erVFaeoVo2OjnLVVVd1exqLivu889znnec+76zNmzdz7rnnQuN3\naTtUjYVbgX/dNPZ5YDPwJ9OEAsDtwFlNY2c0xmfyHMDq1asZHh6uOEW1amhoyP3dYe7zznOfd577\nvGvadhq/Uixk5tPAXVPHIuJp4InM3Nz4+lLglzJz970UrgU+FBGXA58DTgXOBt4yz7lLkqQOaMcd\nHJuPJhwKrPz5k5kPAG8FTgM2Un/L5Acys/kdEpIkqQdVfjdEs8x8c9PX50+zzAbq1ztIkqQ+42dD\n6OdqtVq3p7DouM87z33eee7z/hfTX5PYXRExDIyPj497UYwkSRVMTEwwMjICMJKZE+14TY8sSJKk\nImNBkiQVGQuSJKnIWJAkSUXGgiRJKjIWJElSkbEgSZKK5n0Hx4X01LNPdXsKkiT1heefh3vugZtv\nbv9r93QsnPqFU1l++3LWLlvLmoPXsHbZWtYespY1h6zhoH0P6vb0JEnquN1RcNddsGlT/XHXXfCD\nH8DOnQuzzZ6+g+NlX7yMZw55hru238Wm7ZvY8sQWdmZ9Tyzfz4iQJA2uuUTBihWwdm39sWZN/b8v\nvjjBm9/c3js49nQsNN/u+fmfPc+WJ7ew6fFNbNq+yYiQJPW9VqNgzRo48MCXvt5C3O65p09DNFuy\n9xLWLVvHumXr9hifLiJuvf9WPvPdzxgRkqSeUCUKzjwTRkfLUdBJfRULMzEiJEm9op+jYCYDEQsz\nMSIkSQtlEKNgJgMdCzMxIiRJc7WYomAmizIWZmJESNLiZRTMzFiYAyNCkgaHUVCdsTAPRoQk9S6j\noH2MhQVgREhS5xgFC89Y6CAjQpJaZxR0j7HQA4wISfoFo6D3GAs9zIiQNMiMgv5hLPQhI0JSPzEK\n+p+xMECMCEndZBQMLmNhETAiJLWTUbD4GAuLmBEhqcQo0G6VYiEiLgQuAg5vDG0CPp6ZN82w/MnA\n15uGEzg0Mx+vNlV1ihEhLS5GgWZT9cjCw8BHgS1AAOcBfx8Rx2Tm5hnWSeB1wE9/PmAo9CUjQupv\nRoFaVSkWMvMfm4b+ICIuAo4DZooFgO2ZuaPq5NQfjAiptxgFareWr1mIiL2A9wD7AreXFgU2RsRS\n4PvAH2bmt1vdrvqHESEtLKNAnVI5FiJiHfU4WEr91MI7M/PuGRZ/FPgg8F1gCXABcFtE/Gpmbmxt\nyup3RoRUjVGgbovMrLZCxN7ALwNDwNnUA+CkQjA0r38b8GBmri8sMwyMn3TSSQwNDe3xXK1Wo1ar\nVZqz+tt0EbFp+ya2PLHFiNBAqRIFu2PAKFjcxsbGGBsb22NscnKSDRs2AIxk5kQ7tlM5Fl7yAhFf\nAX6QmRfNcflPACdk5gmFZYaB8fHxcYaHh+c1Pw0uI0L9yijQQpqYmGBkZATaGAvtuM/CXtRPMczV\nMdRPT0jz4ukM9TpPH2hQVL3PwqXAPwEPAa8EzgFOBs5oPH8ZcNjuUwwRcQlwP/X7MSylfsriFOD0\nNs1fegkjQp1mFGjQVT2ysAy4HjgUmATuBM7IzK81nl8BrJyy/D7AlcBhwDON5U/NzA3zmbTUCiNC\n82UUaLGa9zULC8FrFtQLvCZi8fKaAvWzXr1mQRpIHokYfB4pkObGWJAqMiL6j1EgzY+xILWJEdF9\nRoG0MIwFaYEZEe1nFEidZSxIXWJEzM4okHqDsSD1mMUYEUaB1NuMBalPDEJEGAVSfzIWpD7XixFh\nFEiDxViQBlQnIsIokBYHY0FaZOYTEUMvW86rXlzLXk+u4en717J901p2bVsDzx5kFEgDzFiQBNQj\n4sihdex6bB25DXIT7NoEO+9+nvt+soVdB21ictkmnnv1Xbzs0Ft59tjPkG+oR8SyfZezZvlaVh+8\nhtXL1rLmkLWsPmQNB/b4hZWS5sZYkBahKqcPzjp9CWvWrGPt2nV7HCnopwsrJc2PsSANsIW8pqAX\nL6yUtDCMBWkA9NKFhkaENHiMBamP9FIUVGVESP3LWJB6UD9HQVVGhNT7jAWpixZTFFRlREi9w1iQ\nOsAoaB8jQuo8Y0FqI6Oge4wIaeEYC1ILjIL+YURI82csSAVGweAyIqS5MxYkjAL9ghEhvZSxoEXF\nKFCrjAgtZsaCBpJRoE4xIrQY9HYsbN7c7Rmox73wAjz4IGzdCvfdV//v1q3w8MOwc1d9mYMPglWr\n4PjXw6p31/+8ahUMDU3zgg80HtI8LQHWAes4EoaOhKF3wGvhhZ+9wEM7HmLrk1u57yf3sfWRrWy9\n60bueOoadmb9h/agVxzIEQcewWsOeA1HHHgEq161ilUHrOKAVxzQ1e9JfWIBfndGZrb9RecrIoaB\n8XFguNuTkSSpj0wAI/U/jmTmRDtes7ePLNxwA6xe3e1ZqIOqHCk44ohfHCWY8UiB1OdeciTiJ1vZ\n+tRWHnrqIY9EaHqbN8O557b1JXs7FlavhmGPLQyiKtcUrH07nLnGawq0OO0DvJbjeG3T+HTXRHxj\n+51s2fq/vCZCbVcpFiLiQuAi4PDG0Cbg45l5U2GdNwFXAmuBh4A/zszrW5ms+o8XGkoLwwsr1UlV\njyw8DHwU2AIEcB7w9xFxTGa+5IqKiDgcuBG4BngfcBpwXUQ8kplfaX3a6jVGgdQbjAgthHlf4BgR\nTwD/OTP/cprnLgfOysx/M2VsDBjKzLcUXrN+geP4OMOehugplU4fNGLAKJB613QRsWn7JrY8scWI\n6FMTExOMjIxAL1zgGBF7Ae8B9gVun2Gx44Bbm8ZuBq5qdbvqDI8USIuDRyI0F5VjISLWUY+DpcBP\ngXdm5t0zLL4C2NY0tg3YPyKWZObzVbev9jIKJE3HiNBUlU9DRMTewC8DQ8DZwAXASdMFQ0TcA3wu\nMy+fMnYW9esY9p0pFnafhjjppJMYano/XK1Wo1arVZqzPH0gaWF5OqM7xsbGGBsb22NscnKSDRs2\nQBtPQ7TjmoWvAD/IzIumee4bwHhmfnjK2HnAVZn5qsJres1Ci4wCSb3EiOi8nrpmYYq9qN/ZdDq3\nA2c1jZ3BzNc4aI48fSCpH3g6YzBUvc/CpcA/Ub9fwiuBc4CTqQcAEXEZcFhmrm+sci3woca7Ij4H\nnEr91MWM74TQnowCSYPIiOgvVY8sLAOuBw4FJoE7gTMy82uN51cAK3cvnJkPRMRbqb/74XeBHwIf\nyMzmd0gsekaBJBkRvaq3P0hqAK9Z8JoCSWofr4l4qV69ZkHT8EiBJC08j0R0hrEwT0aBJPUeI6K9\njIU5Mgokqf8ZEa0xFpoYBZK0+BgRZYs2FowCSdJsjIi6gY8Fo0CS1G6LLSIGJhaMAklStw1qRPRd\nLBgFkqR+0+8R0dM3Zfqbvxknc9ibF0mSFpX53GzqwbsfbPtNmXo6FmAcGDYKJElibhFx4E8O5Mmr\nn4TFcgfH666Dd77TKJAkCeZ2OuPWb93KdVzX1u32dCy8/vWGgiRJs5kaEUe+cGTbY2Gvtr6aJEka\nOMaCJEkqMhYkSVKRsSBJkoqMBUmSVGQsSJKkImNBkiQVGQuSJKnIWJAkSUXGgiRJKjIWJElSkbEg\nSZKKjAVJklRkLEiSpCJjQZIkFVWKhYj4/Yj4TkTsiIhtEfF3EfG6WdY5OSJ2NT12RsSy+U1dkiR1\nQtUjCycCfwb8GnAa8HLgloh4xSzrJXAksKLxODQzH6+4bUmS1AV7V1k4M98y9euIOA94HBgBvjnL\n6tszc0el2UmSpK6b7zULB1A/avDkLMsFsDEiHomIWyLijfPcriRJ6pCWYyEiAvgU8M3MvKuw6KPA\nB4F3A+8CHgZui4hjWt22JEnqnEqnIZpcA6wBTigtlJn3AvdOGbojIo4ARoH189i+JEnqgJZiISL+\nHHgLcGJmPtrCS3yHWSIDYHR0lKGhoT3GarUatVqthU1KkjRYxsbGGBsb22NscnKy7duJzKy2Qj0U\n3g6cnJlbW9poxC3Ajsw8e4bnh4Hx8fFxhoeHW9mEJEmL0sTEBCMjIwAjmTnRjtesdGQhIq4BasDb\ngKcjYnnjqcnMfK6xzKXAL2Xm+sbXlwD3A5uApcAFwCnA6e34BiRJ0sKqehriQurvfritafx84AuN\nPx8KrJzy3D7AlcBhwDPAncCpmbmh6mQlSVLnVb3PwqzvnsjM85u+vgK4ouK8JElSj/CzISRJUpGx\nIEmSiowFSZJUZCxIkqQiY0GSJBUZC5IkqchYkCRJRcaCJEkqMhYkSVKRsSBJkoqMBUmSVGQsSJKk\nImNBkiQVGQuSJKnIWJAkSUXGgiRJKjIWJElSkbEgSZKKjAVJklRkLEiSpCJjQZIkFRkLkiSpyFiQ\nJElFxoIkSSoyFiRJUpGxIEmSiowFSZJUZCxIkqSiSrEQEb8fEd+JiB0RsS0i/i4iXjeH9d4UEeMR\n8VxE3BsR61ufsiRJ6qSqRxZOBP4M+DXgNODlwC0R8YqZVoiIw4Ebga8CRwNXA9dFxOktzFeSJHXY\n3lUWzsy3TP06Is4DHgdGgG/OsNpFwNbM/Ejj63si4teBUeArlWYrSZI6br7XLBwAJPBkYZnjgFub\nxm4Gjp/ntiVJUge0HAsREcCngG9m5l2FRVcA25rGtgH7R8SSVrcvSZI6o9JpiCbXAGuAE9o0l5cY\nHR1laGhoj7FarUatVluoTUqS1DfGxsYYGxvbY2xycrLt24nMrL5SxJ8DvwGcmJkPzbLsN4DxzPzw\nlLHzgKsy81UzrDMMjI+PjzM8PFx5fpIkLVYTExOMjIwAjGTmRDtes/JpiEYovB04ZbZQaLgdOLVp\n7IzGuCRJ6nFV77NwDXAO8D7g6YhY3ngsnbLMpRFx/ZTVrgVWRcTlEXFURFwMnA18sg3zlyRJC6zq\nkYULgf2B24BHpjzeM2WZQ4GVu7/IzAeAt1K/L8NG6m+Z/EBmNr9DQpIk9aCq91mYNS4y8/xpxjZQ\nvxeDJEnqM342hCRJKjIWJElSkbEgSZKKjAVJklRkLEiSpCJjQZIkFRkLkiSpyFiQJElFxoIkSSoy\nFiRJUpGxIEmSiowFSZJUZCxIkqQiY0GSJBUZC5IkqchYkCRJRcaCJEkqMhYkSVKRsSBJkoqMBUmS\nVGQsSJKkImNBkiQVGQuSJKnIWJAkSUXGgiRJKjIWJElSkbEgSZKKjAVJklRUORYi4sSI+HJE/Cgi\ndkXE22ZZ/uTGclMfOyNiWevTliRJndLKkYX9gI3AxUDOcZ0EjgRWNB6HZubjLWxbkiR12N5VV8jM\nm4CbACIiKqy6PTN3VN2eJEnqrk5dsxDAxoh4JCJuiYg3dmi7kiRpnjoRC48CHwTeDbwLeBi4LSKO\n6cC2JUnSPFU+DVFVZt4L3Dtl6I6IOAIYBdaX1h0dHWVoaGiPsVqtRq1Wa/s8JUnqN2NjY4yNje0x\nNjk52fbtROZcr1GcZuWIXcA7MvPLFdf7BHBCZp4ww/PDwPj4+DjDw8Mtz0+SpMVmYmKCkZERgJHM\nnGjHa3brPgvHUD89IUmSelzl0xARsR/wWuoXLQKsioijgScz8+GIuAw4LDPXN5a/BLgf2AQsBS4A\nTgFOb8P8JUnSAmvlmoVjga9Tv3dCAlc2xq8H3k/9Pgorpyy/T2OZw4BngDuBUzNzQ4tzliRJHdTK\nfRa+QeH0RWae3/T1FcAV1acmSZJ6gZ8NIUmSiowFSZJUZCxIkqQiY0GSJBUZC5IkqchYkCRJRcaC\nJEkqMhYkSVKRsSBJkoqMBUmSVGQsSJKkImNBkiQVGQuSJKnIWJAkSUXGgiRJKjIWJElSkbEgSZKK\njAVJklRkLEiSpCJjQZIkFRkLkiSpyFiQJElFxoIkSSoyFiRJUpGxIEmSiowFSZJUZCxIkqQiY0GS\nJBVVjoWIODEivhwRP4qIXRHxtjms86aIGI+I5yLi3ohY39p0JUlSp7VyZGE/YCNwMZCzLRwRhwM3\nAl8FjgauBq6LiNNb2LYkSeqwvauukJk3ATcBRETMYZWLgK2Z+ZHG1/dExK8Do8BXqm5fkiR1Vieu\nWTgOuLVp7Gbg+A5sW5IkzVMnYmEFsK1pbBuwf0Qs6cD2JUnSPFQ+DdFJo6OjDA0N7TFWq9Wo1Wpd\nmpEkSb1jbGyMsbGxPcYmJyfbvp1OxMJjwPKmseXAjsx8vrTiVVddxfDw8IJNTJKkfjbdP6AnJiYY\nGRlp63Y6cRriduDUprEzGuOSJKnHtXKfhf0i4uiIOKYxtKrx9crG85dFxPVTVrm2sczlEXFURFwM\nnA18ct6zlyRJC66VIwvHAv8XGKd+n4UrgQngjxrPrwBW7l44Mx8A3gqcRv3+DKPABzKz+R0SkiSp\nB7Vyn4VvUIiMzDx/mrENQHtPoEiSpI7wsyEkSVKRsSBJkoqMBUmSVGQsSJKkImNBkiQVGQuSJKnI\nWJAkSUXGgiRJKjIWJElSkbEgSZKKjAVJklRkLEiSpCJjQZIkFRkLkiSpyFiQJElFxoIkSSoyFiRJ\nUpGxIEmSiowFSZJUZCxIkqQiY0GSJBUZC5IkqchYkCRJRcaCJEkqMhYkSVKRsSBJkoqMBUmSVNRS\nLETEhyLi/oh4NiLuiIg3FJY9OSJ2NT12RsSy1qctSZI6pXIsRMRvAVcCHwNeD3wPuDkiDi6slsCR\nwIrG49DMfLz6dCVJUqe1cmRhFPhsZn4hM+8GLgSeAd4/y3rbM/Px3Y8WtitJkrqgUixExMuBEeCr\nu8cyM4FbgeNLqwIbI+KRiLglIt7YymQlSVLnVT2ycDDwMmBb0/g26qcXpvMo8EHg3cC7gIeB2yLi\nmIrbliRJXbD3Qm8gM+8F7p0ydEdEHEH9dMb6hd6+JEman6qx8GNgJ7C8aXw58FiF1/kOcMJsC42O\njjI0NLTHWK1Wo1arVdiUJEmDaWxsjLGxsT3GJicn276dqF9yUGGFiDuAf87MSxpfB/AQ8KeZecUc\nX+MWYEdmnj3D88PA+Pj4OMPDw5XmJ0nSYjYxMcHIyAjASGZOtOM1WzkN8Ung8xExTv0IwSiwL/B5\ngIi4DDgsM9c3vr4EuB/YBCwFLgBOAU6f7+QlSdLCqxwLmfmlxj0VPk799MNG4MzM3N5YZAWwcsoq\n+1C/L8Nh1N9ieSdwamZumM/EJUlSZ7R0gWNmXgNcM8Nz5zd9fQUwp9MTkiSp9/jZEJIkqchYkCRJ\nRcaCJEkqMhYkSVKRsSBJkoqMBUmSVGQsSJKkImNBkiQVGQuSJKnIWJAkSUXGgiRJKjIWJElSkbEg\nSZKKjAVJklRkLEiSpCJjQZIkFRkLkiSpyFiQJElFxoIkSSoyFiRJUpGxIEmSiowFSZJUZCxIkqQi\nY0GSJBUZC5IkqchYkCRJRcaCJEkqMhb0c2NjY92ewqLjPu8893nnuc/7X0uxEBEfioj7I+LZiLgj\nIt4wy/JviojxiHguIu6NiPWtTVcLyf9Dd577vPPc553nPu9/lWMhIn4LuBL4GPB64HvAzRFx8AzL\nHw7cCHwVOBq4GrguIk5vbcqSJKmTWjmyMAp8NjO/kJl3AxcCzwDvn2H5i4CtmfmRzLwnMz8N/G3j\ndSRJUo+rFAsR8XJghPpRAgAyM4FbgeNnWO24xvNT3VxYXpIk9ZC9Ky5/MPAyYFvT+DbgqBnWWTHD\n8vtHxJLMfH6adZYCbN68ueL0NB+Tk5NMTEx0exqLivu889znnec+76wpvzuXtus1q8ZCpxwOcO65\n53Z5GovPyMhIt6ew6LjPO8993nnu8644HPh2O16oaiz8GNgJLG8aXw48NsM6j82w/I4ZjipA/TTF\nOcADwHMV5yhJ0mK2lHoo3NyuF6wUC5n5YkSMA6cCXwaIiGh8/aczrHY7cFbT2BmN8Zm28wTw11Xm\nJkmSfq4tRxR2a+XdEJ8ELoiI346IXwGuBfYFPg8QEZdFxPVTlr8WWBURl0fEURFxMXB243UkSVKP\nq3zNQmZ+qXFPhY9TP52wETgzM7c3FlkBrJyy/AMR8VbgKuB3gR8CH8jM5ndISJKkHhT1dz5KkiRN\nz8+GkCRJRcaCJEkq6kos+EFUnVdln0fEOyPiloh4PCImI+LbEXFGJ+c7CKr+nE9Z74SIeDEivItN\nRS383bJPRPxxRDzQ+Ptla0Sc16HpDoQW9vk5EbExIp6OiEci4i8i4sBOzbffRcSJEfHliPhRROyK\niLfNYZ15/w7teCz4QVSdV3WfAycBt1B/y+sw8HXgHyLi6A5MdyC0sM93rzcEXM9Lb5GuWbS4z/8n\ncApwPvA6oAbcs8BTHRgt/H1+AvWf7/8BrKH+zrhfBf57RyY8GPaj/saCi4FZLzps2+/QzOzoA7gD\nuHrK10H9HRIfmWH5y4E7m8bGgP/d6bn366PqPp/hNb4P/EG3v5d+ebS6zxs/239E/S/fiW5/H/30\naOHvln8LPAkc0O259+ujhX3+n4AtTWO/AzzU7e+lHx/ALuBtsyzTlt+hHT2y4AdRdV6L+7z5NQJ4\nJfW/WDWLVvd5RJwPvIZ6LKiCFvf5bwDfBT4aET+MiHsi4oqIaNv99AdZi/v8dmBlRJzVeI3lwG8C\n/7iws13U2vI7tNOnIUofRLVihnWKH0TV3ukNpFb2ebP/Qv3Q15faOK9BVnmfR8SRwKXAOZm5a2Gn\nN5Ba+TlfBZwIrAXeAVxC/bD4pxdojoOm8j7PzG8D5wJfjIgXgEeBn1A/uqCF0Zbfob4bQkUR8T7g\nvwG/mZk/7vZ8BlFE7AX8FfCxzLxv93AXp7RY7EX9MO77MvO7mXkT8GFgvf8QWRgRsYb6OfM/pH49\n1JnUj6Z9tovT0hx0+lMnO/VBVPqFVvY5ABHxXuoXHp2dmV9fmOkNpKr7/JXAscAxEbH7X7V7UT8D\n9AJwRmbetkBzHRSt/Jw/CvwoM/9lythm6qH2auC+adfSbq3s898DvpWZu2/3//3GRwD8n4j4r5nZ\n/C9gzV9bfod29MhCZr4I7P4gKmCPD6Ka6UMvbp+6fEPxg6j0Cy3ucyKiBvwF8N7Gv7g0Ry3s8x3A\nOuAY6lcrH039M1Xubvz5nxd4yn2vxZ/zbwGHRcS+U8aOon604YcLNNWB0eI+3xf4WdPYLupX9Xs0\nbWG053doF67efA/wDPDbwK9QP/z0BHBI4/nLgOunLH848FPqV3QeRf3tIi8Ap3X7StR+ebSwz9/X\n2McXUi/Q3Y/9u/299Muj6j6fZn3fDbHA+5z6dTgPAl8EVlN/y/A9wLXd/l765dHCPl8PPN/4u+U1\nwAnAd4Bvd/t76ZdH4+f2aOr/uNgF/MfG1ytn2Odt+R3arW/2YuAB4FnqdXPslOf+Evha0/InUS/Y\nZ4EtwL/r9v9g/faoss+p31dh5zSPz3X7++inR9Wf86Z1jYUO7HPq91a4GfiXRjh8AljS7e+jnx4t\n7PMPAf+vsc9/SP2+C4d2+/volwdwciMSpv37eaF+h/pBUpIkqch3Q0iSpCJjQZIkFRkLkiSpyFiQ\nJElFxoIkSSoyFiRJUpGxIEmSiowFSZJUZCxIkqQiY0GSJBUZC5Ikqej/A4+hdN2KbSrmAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x92c8f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal:\n",
      "['Peek', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'Peek', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'Peek', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'Peek', 'SelectClubs', 'SelectDiamonds', 'Peek', 'SelectClubs', 'Peek', 'Peek', 'SelectClubs', 'Peek', 'SelectDiamonds', 'Peek', 'SelectClubs', 'SelectClubs']\n",
      "\n",
      "MLS:\n",
      "['SelectClubs', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs']\n",
      "\n",
      "AV:\n",
      "['SelectClubs', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectDiamonds', 'SelectClubs', 'SelectClubs', 'SelectClubs']\n",
      "\n",
      "Q-MDP:\n",
      "['Peek', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'Peek', 'Peek', 'Peek', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'SelectClubs', 'Peek', 'Peek', 'SelectClubs', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'Peek', 'SelectClubs', 'Peek', 'Peek', 'Peek']\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "import matplotlib.pyplot as plt\n",
    "a1=[2.795, 3.795]\n",
    "a2=[3.795, 2.795]\n",
    "a3=[3.105, 3.105]\n",
    "plt.plot(a1)\n",
    "plt.plot(a2)\n",
    "plt.plot(a3)\n",
    "\n",
    "\n",
    "mins=[]\n",
    "for b in unique_belief_list:\n",
    "    ab1 = b[0].dot(a1)\n",
    "    ab2 = b[0].dot(a2)\n",
    "    ab3 = b[0].dot(a3)\n",
    "    actval =[ab1, ab2, ab3]\n",
    "\n",
    "    if actval.index(min(actval))==0:\n",
    "        mins+=[\"SelectClubs\"]\n",
    "    elif actval.index(min(actval))==1:\n",
    "        mins+=[\"SelectDiamonds\"]\n",
    "    else:\n",
    "        mins+=[\"Peek\"]\n",
    "    \n",
    "    #plt.plot([ab1, ab2, ab3])\n",
    "\n",
    "plt.axis([0, 1, 0, 4])\n",
    "plt.show()\n",
    "\n",
    "print \"\\nOptimal:\"    \n",
    "print mins  \n",
    "\n",
    "print \"\\nMLS:\"    \n",
    "print mls\n",
    "\n",
    "print \"\\nAV:\"   \n",
    "print av\n",
    "\n",
    "print \"\\nQ-MDP:\"    \n",
    "print qmdp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As heuristicas MLS e AV tem apenas em consideraçao a politica escolhendo sempre a acçao guess e por isso terao uma incerteza inferior a heuristica Q-MDP que pode fazer peek no entanto isto nao é ideal, na activity 6 como utilizamos a optimal cost to go apenas escolhemos a acçao guess quando a certeza tem um valor proximo de 0,5 (quando incerteza é grande)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
